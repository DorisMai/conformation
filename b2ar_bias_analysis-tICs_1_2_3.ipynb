{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this iPython notebook, we will featurize MOR ligand binding simulation by pairwise distances between the ligand and different receptor residues. We will then perform tICA and prospectively build an MSM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# changing matplotlib the default style\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from PDB_Order_Fixer import PDB_Order_Fixer\n",
    "import mdtraj as md\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import copy\n",
    "from functools import partial \n",
    "import operator\n",
    "import time\n",
    "\n",
    "import random \n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "import sys\n",
    "from io_functions import *\n",
    "from custom_clusterer import *\n",
    "from custom_tica import *\n",
    "from custom_featurizer import *\n",
    "from pdb_editing import *\n",
    "from analysis import *\n",
    "from io_functions import *\n",
    "#from topology_fixing import *\n",
    "from subsampling import *\n",
    "from conversions import *\n",
    "from custom_msm import *\n",
    "from grids import *\n",
    "from docking_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from detect_intermediates import *\n",
    "from interpret_tICs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_importances_df(importances, titles, scaled=False):\n",
    "    if scaled:\n",
    "        return pd.DataFrame(np.mean(np.vstack(list(importances)), axis=0), index = titles + [\"%s_scaled\" %n for n in titles], columns=[\"importance\"]).sort(\"importance\", inplace=False, ascending=False)\n",
    "    else: \n",
    "        return pd.DataFrame(np.mean(np.vstack(list(importances)), axis=0), index = titles, columns=[\"importance\"]).sort(\"importance\", inplace=False, ascending=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from b2ar_feature_types import *\n",
    "from get_variable_names import *\n",
    "from b2ar_tica_config import *\n",
    "from residue import Residue, Atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import scale\n",
    "from random import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ori_feature_name = copy.deepcopy(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#schemes = [\"closest-heavy\", \"CA\"]\n",
    "#feature_name = \"%s-CA\" %ori_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rho = 0.01\n",
    "rho_string = \"_rho0pt01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(active_ref_dir, inactive_ref_dir, simulation_ref_dir, scripts_dir,\n",
    "          ligand_dir, agonist_dir, inverse_agonist_dir, biased_agonist_dir, ref_receptors_dir, whole_trajectory_pnas,\n",
    "          sasa_file) = get_base_files(base)\n",
    "\n",
    "tica_dir = get_tica_dir(base, is_sparse, lag_time, n_components, feature_name, \n",
    "                                 wolf_string, shrinkage_string, rho_string)\n",
    "ori_tica_dir = copy.deepcopy(tica_dir)\n",
    "features_dir = get_features_dir(base, feature_name)\n",
    "\n",
    "landmarks_dir = get_landmarks_dir(tica_dir)\n",
    "analysis_dir = get_analysis_dir(tica_dir, n_clusters, sampling_method)\n",
    "gmm_dir = get_gmm_dir(tica_dir)\n",
    "rf_dirdir = get_rf_dir(tica_dir)\n",
    "\n",
    "\n",
    "ref_tica_dir, ref_tica_coords = get_ref_tica_dirs(tica_dir)\n",
    "\n",
    "graph_file = get_graph_file(tica_dir, msm_lag_time, n_clusters)\n",
    "\n",
    "pnas_titles =  [\"tm6_tm3_dist\", \"rmsd_npxxy_inactive\", \"rmsd_npxxy_active\", \"rmsd_connector_inactive\", \"rmsd_connector_active\"]\n",
    "pnas_features_dir = analysis_dir\n",
    "\n",
    "\n",
    "(clusterer_dir, msm_model_dir, macrostate_dir, features_known, model_dir, projected_features_dir,\n",
    "         projection_operator_dir, ktica_fit_model_filename, ktica_projected_data_filename, nystroem_data_filename,\n",
    "         mutual_information_csv, pearson_csv) = get_tica_files(base, tica_dir, n_clusters, msm_lag_time, n_macrostates)\n",
    "\n",
    "(standardized_features_dir, feature_residues_csv, feature_residues_pkl,\n",
    "          contact_csv, ref_features_dir) = get_feature_files(features_dir)\n",
    "\n",
    "(kmeans_csv, tica_coords_csv, features_csv, active_rmsd_dir, inactive_rmsd_dir, active_pnas_dir, inactive_pnas_joined, active_pnas_joined,\n",
    "        clusters_map_file, ktica_clusters_map_file, analysis_file, combined_file, docking_summary, docking_joined, docking_z_scores_csv,\n",
    "        aggregate_docking, aggregate_docking_joined, docking_pnas_joined, aggregate_docking_pnas, aggregate_docking_pnas_joined, docking_multiple_ligands,\n",
    "        docking_distances_file, docking_pdf, mmgbsa_docking_distances, pnas_coords, mmgbsa_dir, mmgbsa_csv, mmgbsa_pdf, aggregate_mmgbsa,\n",
    "        aggregate_mmgbsa_joined, aggregate_mmgbsa_pnas_joined, mmgbsa_z_scores_csv, active_clusters_csv, intermediate_clusters_csv,\n",
    "        inactive_clusters_csv, pnas_clusters_averages, tica_clusters_averages, tica_classes_csv, tica_samples_csv, subgraph_save_base,\n",
    "        degree_save_base, degree_map_csv, degree_z_map_csv, aggregate_docking_pnas_degree_z_joined, tic_residue_csv, feature_coefs_csv,\n",
    "        duplicated_feature_coefs_csv) = get_analysis_files(analysis_dir, n_clusters, tica_dir, tica_dir, sampling_method, n_samples, precision,\n",
    "                                                           msm_lag_time)\n",
    "\n",
    "(inactive_pnas_distances_dir, active_pnas_distances_dir, active_pnas_all_distances_dir,\n",
    "          inactive_pnas_distances_new_csv, active_pnas_distances_new_csv, active_pnas_joined, active_pnas_means, pnas_coords_dir,\n",
    "          pnas_coords_csv, pnas_all_coords_csv, pnas_coords_hexbin_dir, pnas_coords_co_crystallized_docking_dir,\n",
    "          pnas_coords_active_colors_dir, user_defined_features_file, reaction_coordinates_trajs_file) = get_pnas_files(whole_trajectory_pnas, pnas_features_dir)\n",
    "\n",
    "features_dir = get_features_dir(base, feature_name)\n",
    "\n",
    "\n",
    "\n",
    "graph_file = get_graph_file(tica_dir, msm_lag_time, n_clusters)\n",
    "(scripts_dir, pymol_fixpdb_dir) = get_script_dir(scripts_dir)\n",
    "(save_dir, reimaged_dir, mae_dir, combined_reimaged_dir, grid_dir, docking_dir) = get_docking_dirs(tica_dir, n_clusters, n_components, n_samples, sampling_method, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2202,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tica_object.components_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading \"/home/enf/b2ar_analysis/sparse-tICA_t5_n_components25all_residues_2rh1_3sn6_under_cutoff6A_regularization_wolf_autoShrinkage_rho0pt01/phi_psi_chi2_allprot_tica_coords.h5\"...\n",
      "[ 608.76369352  342.82218117  245.50411087  215.63066628  154.69677355\n",
      "  155.50637752  129.76331383  104.55745741  105.81972363  128.19281613\n",
      "   98.09798731   77.75059767   72.03939041   63.51776034   65.46962409\n",
      "   56.51628841   56.55764827   70.05206467   62.57206504   45.93474676\n",
      "   46.11822305   41.0391746    44.00544067   37.35108      38.67501459]\n"
     ]
    }
   ],
   "source": [
    "tica_object = verboseload(projection_operator_dir)\n",
    "print(tica_object.timescales_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting tIC 1\n",
      "feature_importances_df.shape\n",
      "(5, 7)\n",
      "residue_importances_df.shape\n",
      "(10, 3)\n",
      "       feature_name   res_i   res_j  resid_i  resid_j  importance  \\\n",
      "0   Ile72 To Thr123   Ile72  Thr123       72      123   -1.180972   \n",
      "1   Leu75 To Pro323   Leu75  Pro323       75      323    1.069516   \n",
      "3  Phe332 To Ala335  Phe332  Ala335      332      335    0.763328   \n",
      "4  Ile135 To Gln224  Ile135  Gln224      135      224   -0.662528   \n",
      "2  Phe104 To Glu188  Phe104  Glu188      104      188    0.654189   \n",
      "\n",
      "            feature  \n",
      "0   ILE72 to THR123  \n",
      "1   LEU75 to PRO323  \n",
      "3  PHE332 to ALA335  \n",
      "4  ILE135 to GLN224  \n",
      "2  PHE104 to GLU188  \n",
      "Using dark_background\n",
      "       residue  importance  resid\n",
      "Thr123  Thr123   -1.180972    123\n",
      "Ile72    Ile72   -1.180972     72\n",
      "Pro323  Pro323    1.069516    323\n",
      "Leu75    Leu75    1.069516     75\n",
      "Ala335  Ala335    0.763328    335\n",
      "Phe332  Phe332    0.763328    332\n",
      "Gln224  Gln224   -0.662528    224\n",
      "Ile135  Ile135   -0.662528    135\n",
      "Glu188  Glu188    0.654189    188\n",
      "Phe104  Phe104    0.654189    104\n",
      "Using dark_background\n",
      "Interpreting tIC 2\n",
      "feature_importances_df.shape\n",
      "(10, 7)\n",
      "residue_importances_df.shape\n",
      "(17, 3)\n",
      "       feature_name   res_i   res_j  resid_i  resid_j  importance  \\\n",
      "7  Ala128 To Val216  Ala128  Val216      128      216   -1.457099   \n",
      "0   Leu75 To Pro323   Leu75  Pro323       75      323    1.288608   \n",
      "8  Ala128 To Met279  Ala128  Met279      128      279    1.076218   \n",
      "4  Phe332 To Ala335  Phe332  Ala335      332      335    1.027000   \n",
      "1    Phe89 To Trp99   Phe89   Trp99       89       99    0.888000   \n",
      "9  Val129 To Val222  Val129  Val222      129      222    0.848733   \n",
      "5    Phe61 To Thr66   Phe61   Thr66       61       66    0.705307   \n",
      "2  Val213 To Val216  Val213  Val216      213      216   -0.637757   \n",
      "3  Phe332 To Ile334  Phe332  Ile334      332      334    0.581121   \n",
      "6   His93 To Lys305   His93  Lys305       93      305    0.417727   \n",
      "\n",
      "            feature  \n",
      "7  ALA128 to VAL216  \n",
      "0   LEU75 to PRO323  \n",
      "8  ALA128 to MET279  \n",
      "4  PHE332 to ALA335  \n",
      "1    PHE89 to TRP99  \n",
      "9  VAL129 to VAL222  \n",
      "5    PHE61 to THR66  \n",
      "2  VAL213 to VAL216  \n",
      "3  PHE332 to ILE334  \n",
      "6   HIS93 to LYS305  \n",
      "Using dark_background\n",
      "       residue  importance  resid\n",
      "Leu75    Leu75    1.288608     75\n",
      "Pro323  Pro323    1.288608    323\n",
      "Met279  Met279    1.076218    279\n",
      "Ala335  Ala335    1.027000    335\n",
      "Phe332  Phe332    1.004706    332\n",
      "Ala128  Ala128    0.949553    128\n",
      "Trp99    Trp99    0.888000     99\n",
      "Phe89    Phe89    0.888000     89\n",
      "Val129  Val129    0.848733    129\n",
      "Val222  Val222    0.848733    222\n",
      "Thr66    Thr66    0.705307     66\n",
      "Phe61    Phe61    0.705307     61\n",
      "Val216  Val216   -0.678724    216\n",
      "Val213  Val213   -0.637757    213\n",
      "Ile334  Ile334    0.581121    334\n",
      "Lys305  Lys305    0.417727    305\n",
      "His93    His93    0.417727     93\n",
      "Using dark_background\n",
      "Interpreting tIC 3\n",
      "feature_importances_df.shape\n",
      "(7, 7)\n",
      "residue_importances_df.shape\n",
      "(14, 3)\n",
      "       feature_name   res_i   res_j  resid_i  resid_j  importance  \\\n",
      "6  Gly280 To Thr283  Gly280  Thr283      280      283    2.363325   \n",
      "2  Val114 To Thr164  Val114  Thr164      114      164    1.655296   \n",
      "5  Ser203 To Asn293  Ser203  Asn293      203      293    1.251909   \n",
      "4  Ala198 To Ile201  Ala198  Ile201      198      201    0.924236   \n",
      "3  Tyr185 To Thr195  Tyr185  Thr195      185      195    0.679447   \n",
      "0    Phe89 To Trp99   Phe89   Trp99       89       99   -0.438659   \n",
      "1  Phe104 To Glu188  Phe104  Glu188      104      188    0.405791   \n",
      "\n",
      "            feature  \n",
      "6  GLY280 to THR283  \n",
      "2  VAL114 to THR164  \n",
      "5  SER203 to ASN293  \n",
      "4  ALA198 to ILE201  \n",
      "3  TYR185 to THR195  \n",
      "0    PHE89 to TRP99  \n",
      "1  PHE104 to GLU188  \n",
      "Using dark_background\n",
      "       residue  importance  resid\n",
      "Thr283  Thr283    2.363325    283\n",
      "Gly280  Gly280    2.363325    280\n",
      "Thr164  Thr164    1.655296    164\n",
      "Val114  Val114    1.655296    114\n",
      "Asn293  Asn293    1.251909    293\n",
      "Ser203  Ser203    1.251909    203\n",
      "Ile201  Ile201    0.924236    201\n",
      "Ala198  Ala198    0.924236    198\n",
      "Thr195  Thr195    0.679447    195\n",
      "Tyr185  Tyr185    0.679447    185\n",
      "Trp99    Trp99   -0.438659     99\n",
      "Phe89    Phe89   -0.438659     89\n",
      "Glu188  Glu188    0.405791    188\n",
      "Phe104  Phe104    0.405791    104\n",
      "Using dark_background\n",
      "Interpreting tIC 4\n",
      "feature_importances_df.shape\n",
      "(12, 7)\n",
      "residue_importances_df.shape\n",
      "(24, 3)\n",
      "        feature_name   res_i   res_j  resid_i  resid_j  importance  \\\n",
      "2     Phe89 To Trp99   Phe89   Trp99       89       99    2.068668   \n",
      "6   Glu107 To Thr110  Glu107  Thr110      107      110    1.394653   \n",
      "0    Leu75 To Pro323   Leu75  Pro323       75      323    1.000663   \n",
      "8   Leu167 To Tyr199  Leu167  Tyr199      167      199   -0.951380   \n",
      "1    Val87 To Tyr316   Val87  Tyr316       87      316   -0.933353   \n",
      "7   Met156 To Ser161  Met156  Ser161      156      161    0.914508   \n",
      "5   Phe104 To Glu188  Phe104  Glu188      104      188   -0.818826   \n",
      "9   Ala198 To Ile201  Ala198  Ile201      198      201    0.766072   \n",
      "11  Asp130 To Gln142  Asp130  Gln142      130      142   -0.755161   \n",
      "3    Ala91 To Trp109   Ala91  Trp109       91      109   -0.731690   \n",
      "4   Asn103 To Tyr185  Asn103  Tyr185      103      185   -0.643264   \n",
      "10   His93 To Lys305   His93  Lys305       93      305   -0.425386   \n",
      "\n",
      "             feature  \n",
      "2     PHE89 to TRP99  \n",
      "6   GLU107 to THR110  \n",
      "0    LEU75 to PRO323  \n",
      "8   LEU167 to TYR199  \n",
      "1    VAL87 to TYR316  \n",
      "7   MET156 to SER161  \n",
      "5   PHE104 to GLU188  \n",
      "9   ALA198 to ILE201  \n",
      "11  ASP130 to GLN142  \n",
      "3    ALA91 to TRP109  \n",
      "4   ASN103 to TYR185  \n",
      "10   HIS93 to LYS305  \n",
      "Using dark_background\n",
      "       residue  importance  resid\n",
      "Phe89    Phe89    2.068668     89\n",
      "Trp99    Trp99    2.068668     99\n",
      "Thr110  Thr110    1.394653    110\n",
      "Glu107  Glu107    1.394653    107\n",
      "Leu75    Leu75    1.000663     75\n",
      "Pro323  Pro323    1.000663    323\n",
      "Tyr199  Tyr199   -0.951380    199\n",
      "Leu167  Leu167   -0.951380    167\n",
      "Val87    Val87   -0.933353     87\n",
      "Tyr316  Tyr316   -0.933353    316\n",
      "Ser161  Ser161    0.914508    161\n",
      "Met156  Met156    0.914508    156\n",
      "Phe104  Phe104   -0.818826    104\n",
      "Glu188  Glu188   -0.818826    188\n",
      "Ala198  Ala198    0.766072    198\n",
      "Ile201  Ile201    0.766072    201\n",
      "Asp130  Asp130   -0.755161    130\n",
      "Gln142  Gln142   -0.755161    142\n",
      "Trp109  Trp109   -0.731690    109\n",
      "Ala91    Ala91   -0.731690     91\n",
      "Tyr185  Tyr185   -0.643264    185\n",
      "Asn103  Asn103   -0.643264    103\n",
      "His93    His93   -0.425386     93\n",
      "Lys305  Lys305   -0.425386    305\n",
      "Using dark_background\n",
      "Interpreting tIC 5\n",
      "feature_importances_df.shape\n",
      "(17, 7)\n",
      "residue_importances_df.shape\n",
      "(30, 3)\n",
      "        feature_name   res_i   res_j  resid_i  resid_j  importance  \\\n",
      "9   Tyr174 To Thr195  Tyr174  Thr195      174      195    1.866706   \n",
      "10  Val213 To Val216  Val213  Val216      213      216   -1.358702   \n",
      "0     Phe89 To Trp99   Phe89   Trp99       89       99   -1.345337   \n",
      "5   Met156 To Ser161  Met156  Ser161      156      161    1.216413   \n",
      "8   Ile169 To Tyr199  Ile169  Tyr199      169      199    1.134999   \n",
      "7   Ile169 To Tyr174  Ile169  Tyr174      169      174    1.069908   \n",
      "6   Leu167 To Gln170  Leu167  Gln170      167      170    1.067885   \n",
      "11  Gly280 To Thr283  Gly280  Thr283      280      283   -1.030235   \n",
      "2   Glu107 To Thr110  Glu107  Thr110      107      110    0.959543   \n",
      "3   Trp109 To Tyr316  Trp109  Tyr316      109      316   -0.886761   \n",
      "14   Val48 To Ser319   Val48  Ser319       48      319   -0.851106   \n",
      "13  Phe332 To Ile334  Phe332  Ile334      332      334   -0.765788   \n",
      "16  Ile135 To His269  Ile135  His269      135      269    0.764262   \n",
      "1    Phe89 To Trp109   Phe89  Trp109       89      109   -0.640965   \n",
      "4   Ser111 To Val114  Ser111  Val114      111      114    0.628804   \n",
      "12  Phe289 To Leu311  Phe289  Leu311      289      311   -0.510120   \n",
      "15  Ala134 To Ser143  Ala134  Ser143      134      143    0.362678   \n",
      "\n",
      "             feature  \n",
      "9   TYR174 to THR195  \n",
      "10  VAL213 to VAL216  \n",
      "0     PHE89 to TRP99  \n",
      "5   MET156 to SER161  \n",
      "8   ILE169 to TYR199  \n",
      "7   ILE169 to TYR174  \n",
      "6   LEU167 to GLN170  \n",
      "11  GLY280 to THR283  \n",
      "2   GLU107 to THR110  \n",
      "3   TRP109 to TYR316  \n",
      "14   VAL48 to SER319  \n",
      "13  PHE332 to ILE334  \n",
      "16  ILE135 to HIS269  \n",
      "1    PHE89 to TRP109  \n",
      "4   SER111 to VAL114  \n",
      "12  PHE289 to LEU311  \n",
      "15  ALA134 to SER143  \n",
      "Using dark_background\n",
      "       residue  importance  resid\n",
      "Thr195  Thr195    1.866706    195\n",
      "Tyr174  Tyr174    1.826866    174\n",
      "Val213  Val213   -1.358702    213\n",
      "Val216  Val216   -1.358702    216\n",
      "Trp99    Trp99   -1.345337     99\n",
      "Ser161  Ser161    1.216413    161\n",
      "Met156  Met156    1.216413    156\n",
      "Tyr199  Tyr199    1.134999    199\n",
      "Ile169  Ile169    1.131745    169\n",
      "Gln170  Gln170    1.067885    170\n",
      "Leu167  Leu167    1.067885    167\n",
      "Gly280  Gly280   -1.030235    280\n",
      "Thr283  Thr283   -1.030235    283\n",
      "Thr110  Thr110    0.959543    110\n",
      "Glu107  Glu107    0.959543    107\n",
      "Tyr316  Tyr316   -0.886761    316\n",
      "Val48    Val48   -0.851106     48\n",
      "Ser319  Ser319   -0.851106    319\n",
      "Phe332  Phe332   -0.765788    332\n",
      "Ile334  Ile334   -0.765788    334\n",
      "His269  His269    0.764262    269\n",
      "Ile135  Ile135    0.764262    135\n",
      "Phe89    Phe89   -0.676184     89\n",
      "Trp109  Trp109   -0.653255    109\n",
      "Val114  Val114    0.628804    114\n",
      "Ser111  Ser111    0.628804    111\n",
      "Phe289  Phe289   -0.510120    289\n",
      "Leu311  Leu311   -0.510120    311\n",
      "Ala134  Ala134    0.362678    134\n",
      "Ser143  Ser143    0.362678    143\n",
      "Using dark_background\n"
     ]
    }
   ],
   "source": [
    "import interpret_tICs\n",
    "reload(interpret_tICs)\n",
    "from interpret_tICs import *\n",
    "tic_components_dir = tica_dir\n",
    "important_contact_features = interpret_tIC_components(projection_operator_dir, tic_components_dir, feature_residues_pkl, n_tica_components=5, percentile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tica_coords = verboseload(projected_features_dir)\n",
    "pnas_coords = verboseload(pnas_coords_dir)\n",
    "for pnas_coord in pnas_coords: pnas_coord[:,0]*=7.14\n",
    "tica_names = [\"tIC.%d\" %i for i in range(1,n_components+1)]\n",
    "pnas_names = [\"tm6_tm3_dist\", \"rmsd_npxxy_inactive\", \"rmsd_npxxy_active\", \"rmsd_connector_inactive\", \"rmsd_connector_active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "#plot_histograms(projected_features_dir, analysis_dir, \"tICA histogram\", titles=[\"tIC.%d\" %i for i in range(1,n_components+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lag_time = 10\n",
    "msm_model_dir = \"%s/msm_tICs_1_2_3_n_clusters%dlag_time%d.h5\" % (tica_dir, n_clusters, lag_time)\n",
    "#build_msm(clusterer_tICs_1_2_3_filename, lag_time=lag_time, msm_model_dir=msm_model_dir)\n",
    "msm_object = verboseload(msm_model_dir)\n",
    "prior_counts = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"tm6_tm3_dist\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"Ala59_Leu266\"], bins=100)\n",
    "plt.title(\"Ala59-Leu266\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"Thr66_Leu266\"], bins=100)\n",
    "plt.title(\"Thr66-Leu266\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"Asn148_Leu266\"], bins=100)\n",
    "plt.title(\"Asn148-Leu266\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_name_residues_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cluster_averages_per_feature(clusterer, features):\n",
    "  n_clusters = clusterer.n_clusters \n",
    "  concatenated_clusters = np.concatenate(clusterer.labels_)\n",
    "  concatenated_features = np.concatenate(features)\n",
    "  cluster_averages = np.zeros((n_clusters, concatenated_features.shape[1]))\n",
    "  for i in range(0, n_clusters):\n",
    "    rows = np.where(concatenated_clusters == i)[0]\n",
    "    means = np.mean(concatenated_features[rows,:], axis=0)\n",
    "    cluster_averages[i,:] = means\n",
    "  return cluster_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_coords(sample_indices, coords):\n",
    "    sample_coords = []\n",
    "    for cluster in range(0, np.shape(sample_indices)[0]):\n",
    "        print(\"Looking at cluster %d\" %cluster)\n",
    "        cluster_coords = []\n",
    "        for traj_index_frame_tuple in sample_indices[cluster]:\n",
    "            traj_index = traj_index_frame_tuple[0]\n",
    "            frame = traj_index_frame_tuple[1]\n",
    "            cluster_coords.append(coords[traj_index][frame])\n",
    "        cluster_coords = np.vstack(cluster_coords)\n",
    "        sample_coords.append(cluster_coords)\n",
    "    return sample_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading \"/home/enf/b2ar_analysis/sparse-tICA_t5_n_components25all_residues_2rh1_3sn6_under_cutoff6A_regularization_wolf_autoShrinkage_rho0pt01/clusterer_1000clusters.h5\"...\n"
     ]
    }
   ],
   "source": [
    "clusterer = verboseload(clusterer_dir)\n",
    "cluster_averages = calculate_cluster_averages_per_feature(clusterer, pnas_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_averages = pd.DataFrame(cluster_averages, columns=pnas_names)\n",
    "active_clusters = cluster_averages.loc[(cluster_averages[\"rmsd_npxxy_active\"] < 0.5) & (cluster_averages[\"tm6_tm3_dist\"] > 12.) & (cluster_averages[\"tm6_tm3_dist\"] < 15.)]\n",
    "inactive_clusters = cluster_averages.loc[(cluster_averages[\"rmsd_npxxy_active\"] > 0.5) & (cluster_averages[\"tm6_tm3_dist\"] <10.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data_vs_data(np.concatenate(tica_coords), np.concatenate(pnas_coords), tica_names, pnas_names, analysis_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_columns(tica_dir, projected_features_dir, titles = [\"tIC%d\" %j for j in range(1,11)], tICA = True, scale = 1.0, refcoords_file = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "analyze_docking_results_multiple(docking_dir, precision = \"SP\", ligands = inverse_ligands + biased_ligands + agonist_ligands, summary = docking_multiple_ligands, redo = True)\n",
    "compute_cluster_averages(None, csv_filename=docking_multiple_ligands, save_csv=aggregate_docking)\n",
    "\n",
    "#compute_aggregate_scores(docking_multiple_ligands, inverse_agonists = inverse_ligands, summary = aggregate_docking, z_scores_csv = docking_z_scores_csv)\n",
    "#aggregate_docking_joined_map = convert_csv_to_joined_map(aggregate_docking, aggregate_docking_joined)[0]\n",
    "#aggregate_docking_means = calc_mean(aggregate_docking_joined_map)\n",
    "#write_map_to_csv(aggregate_docking_joined, aggregate_docking_means, [\"cluster\", \"mean_aggregate_docking_z_score\"])\n",
    "#r['do.analysis'](tica_dir, analysis_dir, pnas_coords_csv, tica_coords_csv, features_dir, docking_multiple_ligands)\n",
    "#tics_vs_docking_file = \"%s/tICA_vs_docking_carazolol.pdf\" % analysis_dir\n",
    "#plot_tICs_vs_docking(docking_multiple_ligands, tica_coords_csv, tics_vs_docking_file, chosen_ligand=\"s-carazolol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import interpret_tICs\n",
    "reload(interpret_tICs)\n",
    "from interpret_tICs import *\n",
    "rank_tICs_by_docking_logistic(None, None, analysis_dir, docking_csv=docking_multiple_ligands, tica_coords_csv=tica_coords_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading \"/home/enf/b2ar_analysis/sparse-tICA_t5_n_components25all_residues_2rh1_3sn6_under_cutoff6A_regularization_wolf_autoShrinkage_rho0pt01/clusterer_tICs_1_2_3_100clusters_25samples.h5\"...\n",
      "10901\n",
      "3672\n",
      "6212\n",
      "3168\n",
      "3177\n",
      "5384\n",
      "7894\n",
      "16445\n",
      "5192\n",
      "3866\n",
      "4044\n",
      "11575\n",
      "1385\n",
      "721\n",
      "1619\n",
      "4206\n",
      "4880\n",
      "13472\n",
      "6066\n",
      "2512\n",
      "2038\n",
      "7171\n",
      "1824\n",
      "5156\n",
      "1408\n",
      "7936\n",
      "11175\n",
      "7221\n",
      "3860\n",
      "9125\n",
      "2723\n",
      "1393\n",
      "8853\n",
      "4153\n",
      "2962\n",
      "1391\n",
      "7855\n",
      "7786\n",
      "14378\n",
      "5319\n",
      "8472\n",
      "1924\n",
      "4464\n",
      "2614\n",
      "7758\n",
      "2237\n",
      "2284\n",
      "3434\n",
      "1310\n",
      "19311\n",
      "8812\n",
      "2951\n",
      "1160\n",
      "3099\n",
      "10332\n",
      "4336\n",
      "2608\n",
      "15441\n",
      "6080\n",
      "7420\n",
      "1342\n",
      "9835\n",
      "8791\n",
      "2160\n",
      "18196\n",
      "3346\n",
      "12843\n",
      "7931\n",
      "7043\n",
      "2128\n",
      "2663\n",
      "6591\n",
      "6490\n",
      "2238\n",
      "3944\n",
      "5474\n",
      "2193\n",
      "1615\n",
      "11946\n",
      "11022\n",
      "7126\n",
      "9407\n",
      "8547\n",
      "5133\n",
      "4726\n",
      "1997\n",
      "4205\n",
      "2875\n",
      "7209\n",
      "2523\n",
      "5176\n",
      "1877\n",
      "2005\n",
      "13561\n",
      "11357\n",
      "14318\n",
      "11366\n",
      "4922\n",
      "4817\n",
      "2915\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 100\n",
    "n_samples=25\n",
    "\n",
    "clusterer_tICs_1_2_3_filename = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "clusterer_tICs_1_2_3_map_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_map.json\" %(tica_dir, n_clusters, n_samples)\n",
    "tics_to_cluster = [0, 1, 2]\n",
    "\n",
    "projected_features_tICs_1_2_3_filename = \"%s/projected_features_tICs_1_2_3.h5\" %tica_dir\n",
    "#projected_features = verboseload(projected_features_dir)\n",
    "#projected_features = [f[:, [0, 1, 2]] for f in projected_features]\n",
    "#verbosedump(projected_features, projected_features_tICs_1_2_3_filename)\n",
    "\n",
    "#cluster_minikmeans(tica_dir, projected_features_dir, traj_dir, n_clusters=n_clusters, clusterer_dir=clusterer_tICs_1_2_3_filename, tICs=tics_to_cluster)\n",
    "clusterer_tICs_1_2_3 = verboseload(clusterer_tICs_1_2_3_filename)\n",
    "clusterer_tICs_1_2_3_map = make_clusters_map(clusterer_tICs_1_2_3)\n",
    "samples_dir = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree\" %(tica_dir, n_clusters, n_samples)\n",
    "if not os.path.exists(samples_dir): os.makedirs(samples_dir)\n",
    "#sample_clusters(clusterer_tICs_1_2_3_filename, projected_features_dir, traj_dir, traj_ext, save_dir=samples_dir, n_samples=n_samples, method = sampling_method, clusters_map_file = clusterer_tICs_1_2_3_map_file, tICs=[0, 1, 2], worker_pool=dview)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'important_contact_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-62c1646a8305>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msubsampled_features_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtica_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"subsampled_features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsampled_features_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsampled_features_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mimportant_contact_features_pruned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportant_contact_features_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_non_zero_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportant_contact_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_residues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#subsample_features(features_dir, important_contact_features_indices, important_contact_features_pruned, tic_subsampled_features_file, worker_pool=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'important_contact_features' is not defined"
     ]
    }
   ],
   "source": [
    "import interpret_tICs\n",
    "reload(interpret_tICs)\n",
    "from interpret_tICs import *\n",
    "\n",
    "import pickle\n",
    "with open(feature_residues_pkl, \"rb\") as f:\n",
    "    feature_residues = pickle.load(f)\n",
    "\n",
    "clusterer = clusterer_tICs_1_2_3\n",
    "\n",
    "tic_subsampled_features_file = \"%s/features_subsampled.pkl\" % tica_dir\n",
    "subsampled_features_dir = os.path.join(tica_dir, \"subsampled_features\")\n",
    "if not os.path.exists(subsampled_features_dir): os.makedirs(subsampled_features_dir)\n",
    "important_contact_features_pruned, important_contact_features_indices = find_non_zero_features(important_contact_features[0], feature_residues)\n",
    "#subsample_features(features_dir, important_contact_features_indices, important_contact_features_pruned, tic_subsampled_features_file, worker_pool=None)\n",
    "\n",
    "tica_coords = verboseload(projected_features_dir)\n",
    "user_defined_coords = verboseload(user_defined_features_file)\n",
    "\n",
    "pp_n_components = n_components\n",
    "apriori_dfs = []\n",
    "for array in user_defined_coords:\n",
    "    apriori_dfs.append(pd.DataFrame(array, columns=sorted(feature_name_residues_dict.keys())))\n",
    "tica_dfs = []\n",
    "for array in tica_coords:\n",
    "    tica_dfs.append(pd.DataFrame(array, columns=[\"tIC.%d\" %i for i in range(1,n_components+1)]))\n",
    "\n",
    "cluster_pnas_averages = calculate_cluster_averages_per_feature(clusterer, user_defined_coords)\n",
    "cluster_pnas_averages = pd.DataFrame(cluster_pnas_averages, columns=sorted(feature_name_residues_dict.keys()))\n",
    "\n",
    "cluster_tica_averages = calculate_cluster_averages_per_feature(clusterer, tica_coords)\n",
    "cluster_tica_averages = pd.DataFrame(cluster_tica_averages, columns=[\"tIC.%d\" %i for i in range(1, n_components+1)])\n",
    "cluster_tica_pnas = pd.concat([cluster_pnas_averages, cluster_tica_averages], axis=1).dropna()\n",
    "\n",
    "top_features = load_file(tic_subsampled_features_file)\n",
    "\n",
    "import msm_resampled\n",
    "reload(msm_resampled)\n",
    "from msm_resampled import *\n",
    "clusters_map = make_clusters_map(clusterer)\n",
    "tica_resampled_file = os.path.join(tica_dir, \"tica_msm_lag-time%d_clusters%d_resampled.h5\" %(lag_time, n_clusters))\n",
    "projected_features = verboseload(projected_features_dir)\n",
    "\n",
    "\n",
    "def reweight_features_by_msm(msm_object):\n",
    "    total_samples = 10000\n",
    "    resampled_traj_to_frames_file = os.path.join(tica_dir, \"msm_lag-time%d_prior-counts%s_clusters%d_resampled_%d.h5\" %(lag_time, str(prior_counts), n_clusters, total_samples))\n",
    "    resampled_traj_to_frames = resample_by_msm(total_samples, msm_object, clusters_map, num_trajs, resampled_traj_to_frames_file)\n",
    "\n",
    "    resample_features_by_msm_equilibirum_pop(projected_features, resampled_traj_to_frames, tica_resampled_file)\n",
    "    tica_resampled = verboseload(tica_resampled_file)\n",
    "    pnas_resampled_file = os.path.join(tica_dir, \"pnas_resampled.h5\")\n",
    "    resample_features_by_msm_equilibirum_pop(user_defined_coords, resampled_traj_to_frames, pnas_resampled_file)\n",
    "    pnas_resampled = verboseload(pnas_resampled_file)\n",
    "\n",
    "    resampled_traj_index_pairs = []\n",
    "    for traj in resampled_traj_to_frames.keys():\n",
    "        [resampled_traj_index_pairs.append((traj, frame)) for frame in resampled_traj_to_frames[traj]]\n",
    "\n",
    "\n",
    "    features_eq = resample_features_by_msm_trajectory(top_features, resampled_traj_index_pairs)*10.\n",
    "    tica_eq = pd.DataFrame(tica_resampled, columns=[\"tIC.%d\" %i for i in range(1,n_components+1)])\n",
    "    pnas_eq = pd.DataFrame(pnas_resampled, columns=sorted(feature_name_residues_dict.keys()))\n",
    "    features_eq = pd.concat([features_eq, tica_eq, pnas_eq], axis=1)\n",
    "    features_eq.columns = [str(f) for f in features_eq.columns.values.tolist()]\n",
    "\n",
    "    str_features = list(set([str(g) for l in important_contact_features[1] for g in l]))\n",
    "    f0 = pd.concat([f*10. for f in top_features], axis=0)\n",
    "    f2 = pd.concat([f for f in tica_dfs])\n",
    "    f3 = pd.concat([f for f in apriori_dfs])\n",
    "    prot_lig_features = pd.concat([f0,f2,f3],axis=1)\n",
    "    all_traj_features = [pd.concat([top_features[i]*10., tica_dfs[i], apriori_dfs[i]], axis=1) for i in range(0, len(tica_dfs))]\n",
    "    return features_eq, all_traj_features\n",
    "\n",
    "\n",
    "n_steps = 100000\n",
    "save_file = \"%s/msm_traj_index_pairs.h5\" % (tica_dir)\n",
    "#msm_traj_index_pairs = generate_msm_traj_index_series(msm_object, random.choice(active_clusters.index.values.tolist()), n_steps, bu72_pp_clusters_map, save_file)\n",
    "#msm_traj_index_pairs = verboseload(save_file)\n",
    "features_eq, all_traj_features = reweight_features_by_msm(msm_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_dir = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree\" %(tica_dir, n_clusters, n_samples)\n",
    "samples_indices_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_indices.h5\" %(tica_dir, n_clusters, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msmbuilder.utils import verbosedump, verboseload\n",
    "samples_indices = verboseload(samples_indices_file)\n",
    "tica_coords = verboseload(projected_features_dir)\n",
    "features = load_file_list(get_trajectory_files(features_dir, \".dataset\"), directory = None, ext = None)\n",
    "samples_tica = []\n",
    "samples_pnas = []\n",
    "samples_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#samples_tica = get_sample_coords(samples_indices, tica_coords)\n",
    "samples_tica_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_tica.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "#verbosedump(samples_tica, samples_tica_file)\n",
    "samples_tica = verboseload(samples_tica_file)\n",
    "samples_tica_avg_df = pd.DataFrame([np.mean(t, axis=0) for t in samples_tica], index=[\"cluster%d\" %i for i in range(0,n_clusters)], columns=[\"tIC.%d\" %i for i in range(1, n_components+1)])\n",
    "\n",
    "\n",
    "#samples_pnas = get_sample_coords(samples_indices, pnas_coords)\n",
    "samples_pnas_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_pnas.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "#verbosedump(samples_pnas, samples_pnas_file)\n",
    "samples_pnas = verboseload(samples_pnas_file)\n",
    "samples_pnas_avg_df = pd.DataFrame([np.mean(t, axis=0) for t in samples_pnas], index=[\"cluster%d\" %i for i in range(0,n_clusters)], columns=[\"tm6_tm3_dist\", \"rmsd_npxxy_inactive\", \"rmsd_npxxy_active\", \"rmsd_connector_inactive\", \"rmsd_connector_active\"])\n",
    "\n",
    "\n",
    "\n",
    "#samples_features = get_sample_coords(samples_indices, features)\n",
    "samples_features_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_features.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "#verbosedump(samples_features, samples_features_file)\n",
    "samples_features = verboseload(samples_features_file)\n",
    "samples_features_avg_df = pd.DataFrame([np.mean(t, axis=0) for t in samples_features], index=[\"cluster%d\" %i for i in range(0,n_clusters)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#normalized_features = copy.deepcopy(features)\n",
    "#n = StandardScaler()\n",
    "#normalized_features = n.fit_transform(normalized_features)\n",
    "\n",
    "#samples_normalized_features = get_sample_coords(samples_indices, normalized_features)\n",
    "samples_normalized_features_file = \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_samples_kdtree_features_normalized.h5\" %(tica_dir, n_clusters, n_samples)\n",
    "#verbosedump(samples_normalized_features, samples_normalized_features_file)\n",
    "samples_normalized_features = verboseload(samples_normalized_features_file)\n",
    "samples_normalized_features_avg_df = pd.DataFrame([np.mean(t, axis=0) for t in samples_normalized_features], index=[\"cluster%d\" %i for i in range(0,n_clusters)], columns=[str(f) for f in feature_names])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(feature_residues_pkl, \"rb\") as f:\n",
    "    feature_names = pickle.load(f)\n",
    "feature_strings = [str(feature_name) for feature_name in feature_names]\n",
    "samples_normalized_features_averages = [np.mean(f, axis=0) for f in samples_normalized_features]\n",
    "samples_normalized_features_averages_df = pd.DataFrame(samples_normalized_features_averages, columns=feature_strings)\n",
    "\n",
    "samples_pnas_tica = pd.concat([samples_pnas_avg_df, samples_tica_avg_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_avg_df.sort(\"rmsd_npxxy_active\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_center = \"64.4, 16.9, 11.99\"\n",
    "\n",
    "indices = [0,n_clusters]\n",
    "chosen_receptors = []\n",
    "for i in range(indices[0], indices[1]):\n",
    "  for j in range(0, n_samples):\n",
    "    chosen_receptors.append(\"cluster%d_sample%d\" %(i, j))\n",
    "\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "print(\"biased_ligands\")\n",
    "print(biased_ligands)\n",
    "reimaged_dir = samples_dir\n",
    "mae_dir = reimaged_dir\n",
    "#remove_ter(reimaged_dir)\n",
    "#reorder(reimaged_dir)\n",
    "\n",
    "inverse_ligands = get_ligands(inverse_agonist_dir)\n",
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "\n",
    "agonist_ligands = [a for a in agonist_ligands if \"TA\" not in a and \"ta\" not in a]\n",
    "print(agonist_ligands)\n",
    "mehrdad_dir = \"%s/mehrdad_ligands\" %agonist_dir\n",
    "mehrdad_ligands = get_ligands(mehrdad_dir, \".mol\")\n",
    "\n",
    "grid_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_grids\" %(tica_dir, n_clusters, n_samples)\n",
    "docking_dir =  \"%s/clusterer_tICs_1_2_3_%dclusters_%dsamples_kdtree_docking\" %(tica_dir, n_clusters, n_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agonist_ligands = get_ligands(agonist_dir)\n",
    "print(agonist_ligands)\n",
    "biased_ligands = get_ligands(biased_agonist_dir)\n",
    "print(biased_ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docking_multiple_ligands = \"%s/all_docking_scores.csv\" % docking_dir\n",
    "aggregate_docking = \"%s/aggregate_docking.csv\" % docking_dir\n",
    "print(biased_ligands + agonist_ligands)\n",
    "\n",
    "print(docking_multiple_ligands)\n",
    "\n",
    "#analyze_docking_results_multiple(docking_dir, precision = \"SP\", ligands = biased_ligands + agonist_ligands + mehrdad_ligands + inverse_ligands, summary = docking_multiple_ligands, redo = True)\n",
    "#analyze_docking_results_multiple(docking_dir, precision = \"SP\", ligands = biased_ligands + agonist_ligands, summary = docking_multiple_ligands, redo = True)\n",
    "\n",
    "\n",
    "#compute_cluster_averages(None, csv_filename=docking_multiple_ligands, save_csv=aggregate_docking)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pnas_cluster_averages = calculate_cluster_averages_per_feature(verboseload(clusterer_tICs_1_2_3_filename), verboseload(pnas_coords_dir))\n",
    "tica_cluster_averages = calculate_cluster_averages_per_feature(verboseload(clusterer_tICs_1_2_3_filename), verboseload(projected_features_dir))\n",
    "tica_cluster_averages_msm = tica_cluster_averages[msm_clusters,:]\n",
    "tic_names = [\"tIC.%d\" %i for i in range(1, n_components+1)]\n",
    "tica_cluster_averages_df = pd.DataFrame(tica_cluster_averages_msm, columns=tic_names, index=msm_cluster_names)\n",
    "pnas_cluster_averages_df = pd.DataFrame(pnas_cluster_averages, columns=pnas_titles, index=msm_cluster_names)\n",
    "pnas_cluster_averages_df[\"tm6_tm3_dist\"] = pnas_cluster_averages_df[\"tm6_tm3_dist\"]*7.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_tica_avg_df = pd.read_csv(tica_clusters_averages, sep= \" \").sort_index()\n",
    "samples_pnas_avg_df = pd.read_csv(pnas_clusters_averages, sep= \" \").sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_agg = pd.read_csv(aggregate_docking, index_col=0).dropna()\n",
    "#df_agg = pd.read_csv(docking_multiple_ligands, index_col=0).dropna()\n",
    "df_agg.index = [n.split(\"_\")[0] for n in df_agg.index.values]\n",
    "\n",
    "\n",
    "df_agg.columns = [''.join(e for e in lig if e.isalnum() or e=='-' or e=='_') for lig in df_agg.columns.values]\n",
    "msm_obj = verboseload(msm_model_dir)\n",
    "\n",
    "msm_clusters = msm_obj.mapping_.keys()\n",
    "msm_cluster_names = []\n",
    "msm_cluster_eq_pops = []\n",
    "for cluster_id in msm_clusters:\n",
    "    cluster_name = \"cluster%d\" %cluster_id\n",
    "    if cluster_name in df_agg.index.values:\n",
    "        state_id = msm_obj.mapping_[cluster_id]\n",
    "        msm_cluster_eq_pops.append(msm_obj.populations_[state_id])\n",
    "        msm_cluster_names.append(cluster_name)\n",
    "msm_cluster_eq_pops = np.array(msm_cluster_eq_pops)\n",
    "msm_cluster_deltaG = -0.61 * np.log(msm_cluster_eq_pops)\n",
    "msm_cluster_eq_pops_df = pd.DataFrame(msm_cluster_eq_pops, index=msm_cluster_names)\n",
    "aggregate_docking_msm = df_agg.loc[msm_cluster_names]\n",
    "\n",
    "samples_tica_avg_df = samples_tica_avg_df.loc[msm_cluster_names]\n",
    "samples_pnas_avg_df = samples_pnas_avg_df.loc[msm_cluster_names]\n",
    "samples_top_features_avg_df = samples_normalized_features_avg_df[[str(list(f)) for f in important_contact_features[0]]].loc[msm_cluster_names]\n",
    "print(aggregate_docking_msm.columns)\n",
    "\n",
    "ligand = \"3p0g_lig\"\n",
    "\n",
    "apo_deltaG = msm_cluster_deltaG - (-1.0 * aggregate_docking_msm[ligand].values)\n",
    "\n",
    "apo_populations = np.exp(-1.0*apo_deltaG / 0.61)\n",
    "Z_apo = np.sum(apo_populations)\n",
    "apo_populations = apo_populations / Z_apo\n",
    "apo_eq_pops_df = copy.deepcopy(msm_cluster_eq_pops_df)\n",
    "apo_eq_pops_df[apo_eq_pops_df.columns] = apo_populations.reshape((-1,1))\n",
    "apo_deltaG = -.61 * np.log(apo_populations)\n",
    "\n",
    "msm_cluster_eq_pops = apo_populations\n",
    "msm_cluster_deltaG = apo_deltaG\n",
    "msm_cluster_eq_pops_df = apo_eq_pops_df\n",
    "\n",
    "\n",
    "new_populations = copy.deepcopy(aggregate_docking_msm)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    new_populations[ligand] = np.exp(-1.0*(-1.0*aggregate_docking_msm[ligand].values+msm_cluster_deltaG)/0.61)\n",
    "\n",
    "Z = np.sum(new_populations.values, axis=0)\n",
    "for j, ligand in enumerate(aggregate_docking_msm.columns.values):\n",
    "    new_populations[ligand] = new_populations[ligand].values / Z[j]\n",
    "population_deltas = copy.deepcopy(new_populations)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    population_deltas[ligand] = population_deltas[ligand].values / msm_cluster_eq_pops\n",
    "new_energies = copy.deepcopy(new_populations)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    new_energies[ligand] = -.61 * np.log(new_populations[ligand])\n",
    "delta_delta_g = copy.deepcopy(new_energies)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    delta_delta_g[ligand] = new_energies[ligand].values - msm_cluster_deltaG\n",
    "\n",
    "\n",
    "docking_normalized = copy.deepcopy(aggregate_docking_msm)\n",
    "docking_normalized[docking_normalized.columns.values] = scale(docking_normalized.values)\n",
    "\n",
    "ddg_scaled = copy.deepcopy(delta_delta_g)\n",
    "ddg_scaled[delta_delta_g.columns.values] = scale(delta_delta_g.values)\n",
    "    \n",
    "deltas_tica = pd.concat([delta_delta_g, samples_tica_avg_df, samples_pnas_avg_df, samples_top_features_avg_df], axis=1)\n",
    "\n",
    "#print(deltas_tica.iloc[0:10])\n",
    "\n",
    "\n",
    "docking_normalized[docking_normalized.columns.values] = scale(population_deltas.values)\n",
    "\n",
    "train_biased_antagonists = [\"s-carvedilol\", \"nebivolol\"] \n",
    "train_inverse_agonists = [] #[\"s-carazolol\", \"Ici118551\"]\"\n",
    "\n",
    "train_arrestin_agonists = [\"isoetharine\", \"3p0g_lig\"]\n",
    "train_gprot_agonists = [\"procaterol\"]\n",
    "\n",
    "train_agonists = [\"r_isopreterenol\"] + train_arrestin_agonists + train_gprot_agonists\n",
    "\n",
    "indices = []\n",
    "for biased_antagonist in (train_biased_antagonists):# + train_arrestin_agonists):\n",
    "    for inverse_agonist in train_inverse_agonists:\n",
    "        bias_antagonist_minus_antagonists = delta_delta_g[biased_antagonist].values - delta_delta_g[inverse_agonist].values\n",
    "        #bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "        indices.append(set(np.where(bias_antagonist_minus_antagonists < -0.)[0]))\n",
    "    indices.append(set(np.where(scale(delta_delta_g[biased_antagonist].values) <-1.)[0]))\n",
    "\n",
    "#if train_gprot_agonists is not None:\n",
    "#    for biased_antagonist in train_arrestin_agonists:\n",
    "#        for inverse_agonist in (train_gprot_agonists):\n",
    "#            bias_antagonist_minus_antagonists = delta_delta_g[biased_antagonist].values - delta_delta_g[inverse_agonist].values\n",
    "#            #bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "#            indices.append(set(np.where(bias_antagonist_minus_antagonists < -0.)[0]))\n",
    "#        indices.append(set(np.where(delta_delta_g[biased_antagonist].values <0)[0]))\n",
    "\n",
    "\n",
    "indices = set.intersection(*indices)\n",
    "#bias_antagonist_minus_agonists = deltas_tica[[\" 3p0g_lig\"]].mean(axis=1).values - deltas_tica[train_agonists].mean(axis=1).values\n",
    "#bias_antagonist_minus_agonists = scale(bias_antagonist_minus_agonists)\n",
    "#indices = list(set(np.where(bias_antagonist_minus_antagonists < -.5)[0]))#.tolist()).intersection(set(np.where(bias_antagonist_minus_antagonists > 1.)[0].tolist())))\n",
    "biased_antagonist_states = deltas_tica.iloc[list(indices)]#.intersection(set(np.where(np.max(scale(deltas_tica[train_biased_antagonists].values),axis=1) < -.5)[0])))]\n",
    "print(\"biased antagonist states\")\n",
    "print(indices)\n",
    "\n",
    "#biased_antagonist_states = biased_antagonist_states.loc[biased_antagonist_states[\"tm6_tm3_dist\"] > 12.]\n",
    "\n",
    "indices = []\n",
    "\n",
    "for biased_antagonist in train_agonists:\n",
    "    for inverse_agonist in (train_inverse_agonists):\n",
    "        bias_antagonist_minus_antagonists = delta_delta_g[biased_antagonist].values - delta_delta_g[inverse_agonist].values\n",
    "        bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "        indices.append(set(np.where(bias_antagonist_minus_antagonists < -0.)[0]))\n",
    "        #indices.append(set(np.where(delta_delta_g[inverse_antagonist].values > -.5)[0]))\n",
    "    indices.append(set(np.where(delta_delta_g[biased_antagonist].values <-0.)[0]))\n",
    "indices = set.intersection(*indices)\n",
    "agonist_states = deltas_tica.iloc[list(indices)]#.intersection(set(np.where(np.max(scale(deltas_tica[train_biased_antagonists].values),axis=1) < -.5)[0])))]\n",
    "#agonist_states = agonist_states.loc[agonist_states[\"tm6_tm3_dist\"] > 12.]\n",
    "print(\"agonist states:\")\n",
    "print(indices)\n",
    "\n",
    "indices = []\n",
    "for biased_antagonist in train_arrestin_agonists:\n",
    "    for inverse_agonist in (train_gprot_agonists):\n",
    "        bias_antagonist_minus_antagonists = agonist_states[biased_antagonist].values - agonist_states[inverse_agonist].values\n",
    "        bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "        indices.append(set(np.where(bias_antagonist_minus_antagonists < -0.)[0]))\n",
    "        #indices.append(set(np.where(delta_delta_g[inverse_antagonist].values > -.5)[0]))\n",
    "    indices.append(set(np.where(agonist_states[biased_antagonist].values <-0.)[0]))\n",
    "indices = set.intersection(*indices)\n",
    "arrestin_agonist_states = agonist_states.iloc[list(indices)]#.intersection(set(np.where(np.max(scale(deltas_tica[train_biased_antagonists].values),axis=1) < -.5)[0])))]\n",
    "print(\"arrestin agonist states:\")\n",
    "print(indices)\n",
    "\n",
    "indices = []\n",
    "for biased_antagonist in train_gprot_agonists:\n",
    "    for inverse_agonist in (train_arrestin_agonists):\n",
    "        bias_antagonist_minus_antagonists = agonist_states[biased_antagonist].values - agonist_states[inverse_agonist].values\n",
    "        bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "        indices.append(set(np.where(bias_antagonist_minus_antagonists < -0.)[0]))\n",
    "        #indices.append(set(np.where(delta_delta_g[inverse_antagonist].values > -.5)[0]))\n",
    "    indices.append(set(np.where(agonist_states[biased_antagonist].values <-0.)[0]))\n",
    "indices = set.intersection(*indices)\n",
    "gprot_agonist_states = agonist_states.iloc[list(indices)]#.intersection(set(np.where(np.max(scale(deltas_tica[train_biased_antagonists].values),axis=1) < -.5)[0])))]\n",
    "print(\"gprot agonist states:\")\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inactive_clusters = samples_pnas_tica.loc[samples_pnas_tica[\"tm6_tm3_dist\"] < 11.].index.values\n",
    "print(inactive_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msm_resampled import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "BI_msm_resampled_file = \"%s/msm_tICs_1_2_3_BI167107_eq_resampled.h5\"\n",
    "eq_pops = bi_msm.populations_\n",
    "bi_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=BI_msm_resampled_file, equilibrium_populations=eq_pops)\n",
    "BI_tICA_resampled_file = \"%s/msm_tICs_1_2_3_BI167107_eq_tICA_resampled.h5\"\n",
    "resample_features_by_msm_equilibirum_pop(verboseload(projected_features_dir), bi_traj_to_frames, BI_tICA_resampled_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import analysis\n",
    "reload(analysis)\n",
    "from analysis import *\n",
    "plot_columns(analysis_dir, BI_tICA_resampled_file, titles = [\"tIC%d\" %j for j in range(1,n_components+1)], main=\"BI 167107 MSM\", tICA = True, scale = 1.0, refcoords_file = ref_tica_coords, concatenate=False, reshape=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jointplot_d3\n",
    "reload(jointplot_d3)\n",
    "from jointplot_d3 import *\n",
    "#min_density = min(new_populations[\"3p0g_lig\"].values)\n",
    "min_density=7.0\n",
    "#jointplots(verboseload(BI_tICA_resampled_file)[::1,:], analysis_dir, titles = [\"tIC%d\" %j for j in range(1,n_components+1)], main = \"BI 167107 MSM\", refcoords_file = ref_tica_coords, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2, min_density=min_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from msm_resampled import *\n",
    "from jointplot_d3 import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "apo_msm_resampled_file = \"%s/msm_tICs_1_2_3_apo_eq_resampled.h5\"\n",
    "eq_pops = apo_populations\n",
    "msm_apo_populations = np.zeros(len(eq_pops))\n",
    "for cluster_id in bi_msm.mapping_.keys():\n",
    "    msm_apo_populations[bi_msm.mapping_[cluster_id]] = eq_pops[cluster_id]\n",
    "apo_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=apo_msm_resampled_file, equilibrium_populations=msm_apo_populations)\n",
    "apo_tICA_resampled_file = \"%s/msm_tICs_1_2_3_apo_eq_tICA_resampled.h5\"\n",
    "resample_features_by_msm_equilibirum_pop(verboseload(projected_features_dir), apo_traj_to_frames, apo_tICA_resampled_file)\n",
    "jointplots(verboseload(apo_tICA_resampled_file)[::1,:], analysis_dir, titles = [\"tIC%d\" %j for j in range(1,n_components+1)], main = \"APO MSM\", refcoords_file = ref_tica_coords, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2, min_density=min_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jointplot_d3\n",
    "reload(jointplot_d3)\n",
    "from jointplot_d3 import *\n",
    "from msm_resampled import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "ligands = [\"bisoprolol\", \"nebivolol\"]\n",
    "ligands = [\"N-Cyclopentylbutanephrine\", \"3p0g_lig\", \"salmeterol\", \"salbutamol\", \"r_isopreterenol\", \"r_epinephrine\", \"isoetharine\", \"nebivolol\", \"s-carvedilol\", \"s-carazolol\", \"norepinephrine\", \"ethylnorepinephrine\"]\n",
    "#ligands = [\"Ici118551\", \"propranolol\", \"s-atenolol\", \"pindolol\", \"s-carvedilol\", \"xamoterol\", \"s-carazolol\", \"3p0g_lig\", \"r_isopreterenol\", \"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"isoetharine\"]\n",
    "lig_features_eq = {}\n",
    "for ligand in ligands:\n",
    "    lig_msm_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_resampled.h5\" %(tica_dir, ligand)\n",
    "    eq_pops = new_populations[ligand]\n",
    "    msm_lig_populations = np.zeros(len(eq_pops))\n",
    "    for cluster_id in bi_msm.mapping_.keys():\n",
    "        msm_lig_populations[bi_msm.mapping_[cluster_id]] = eq_pops[cluster_id]\n",
    "    new_msm = copy.deepcopy(bi_msm)\n",
    "    new_msm.populations_ = msm_lig_populations\n",
    "    lig_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=lig_msm_resampled_file, equilibrium_populations=msm_lig_populations)\n",
    "    lig_tICA_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_tICA_resampled.h5\" %(tica_dir, ligand)\n",
    "    #resample_features_by_msm_equilibirum_pop(verboseload(projected_features_dir), lig_traj_to_frames, lig_tICA_resampled_file)\n",
    "    #jointplots(verboseload(lig_tICA_resampled_file)[::1,:], analysis_dir, titles = [\"tIC%d\" %j for j in range(1,n_components+1)], main = \"%s MSM\" %ligand, refcoords_file = ref_tica_coords, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2,min_density=min_density, custom_xlim=[-1500, 1300], custom_ylim=[-1000,1000], max_diff=3.0)\n",
    "    lig_features_eq[ligand], _ = reweight_features_by_msm(new_msm)\n",
    "    #plt.hist(lig_features_eq[\"Asn148_Leu266\"], bins=100, range=[10,45])\n",
    "    #plt.title(\"Asn148-Leu266\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"Asn148_Leu266\"], bins=100, range=[10,45])\n",
    "plt.title(\"Asn148-Leu266\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(lig_features_eq[\"tm6_tm3_dist\"], bins=100, range=[5,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"tm6_tm3_dist\"], bins=100, range=[5,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(lig_features_eq[\"Asn148_Leu266\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"norepinephrine\"][\"Thr66_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"ethylnorepinephrine\"][\"Thr66_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"r_epinephrine\"][\"Asn148_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(0,3.,500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"rmsd_npxxy_active\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"s-carazolol\"][\"rmsd_npxxy_active\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"isoetharine\"][\"Asn148_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"N-Cyclopentylbutanephrine\"][\"Asn148_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"ethylnorepinephrine\"][\"Asn148_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"salbutamol\"][\"Asn148_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 20, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"N-Cyclopentylbutanephrine\"][\"tm6_tm3_dist\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"tm6_tm3_dist\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "thr_x = np.linspace(5, 50, 500)\n",
    "thr_kde1 = stats.gaussian_kde(lig_features_eq[\"3p0g_lig\"][\"Thr66_Leu266\"])\n",
    "thr_kde2 = stats.gaussian_kde(lig_features_eq[\"r_isopreterenol\"][\"Asn148_Leu266\"])\n",
    "thr_dx1 = thr_kde1(thr_x)\n",
    "thr_dx2 = thr_kde2(thr_x)\n",
    "plt.plot(thr_x,thr_dx1-thr_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for measurement in [\"Ala59_Leu266\", \"Thr66_Leu266\", \"Asn148_Leu266\"]:\n",
    "    \"\"\"\n",
    "    iso = lig_features_eq[\"r_isopreterenol\"][measurement]\n",
    "    x = np.linspace(np.min(iso.values), np.max(iso.values), 500)\n",
    "    kde2 = stats.gaussian_kde(iso)\n",
    "    dx2 = kde2(x)\n",
    "    plt.clf()\n",
    "    plt.plot(x, dx2)\n",
    "    plt.title(\"Isopreterenol Eq. Population Frequency\")\n",
    "    plt.xlabel(\"%s closest heavy atom distance\" %str(measurement))\n",
    "    plt.ylabel(\"Eq. Population\")\n",
    "    save_file = \"%s/%s_isopreterenol_kde.pdf\" %(analysis_dir, measurement)\n",
    "    plt.savefig(save_file)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.hist(iso, range=[np.min(iso.values), np.max(iso.values)], bins=100)\n",
    "    plt.title(\"Isopreterenol Eq. Population Frequency\")\n",
    "    plt.xlabel(\"%s closest heavy atom distance\" %str(measurement))\n",
    "    plt.ylabel(\"Eq. Population\")\n",
    "    save_file = \"%s/%s_isopreterenol_hist.pdf\" %(analysis_dir, measurement)\n",
    "    plt.savefig(save_file)\n",
    "    \"\"\"\n",
    "    cara = lig_features_eq[\"s-carazolol\"][measurement]\n",
    "    c = np.linspace(np.min(cara.values), np.max(cara.values), 500)\n",
    "    kde2 = stats.gaussian_kde(cara)\n",
    "    dc2 = kde2(c)\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(c, dc2)\n",
    "    plt.title(\"s-carazolol Eq. Population Frequency\")\n",
    "    plt.xlabel(\"%s closest heavy atom distance\" %str(measurement))\n",
    "    plt.ylabel(\"Eq. Population\")\n",
    "    save_file = \"%s/%s_carazolol_kde.pdf\" %(analysis_dir, measurement)\n",
    "    plt.savefig(save_file)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.hist(cara, range=[np.min(iso.values), np.max(iso.values)], bins=100)\n",
    "    plt.title(\"Carazolol Eq. Population Frequency\")\n",
    "    plt.xlabel(\"%s closest heavy atom distance\" %str(measurement))\n",
    "    plt.ylabel(\"Eq. Population\")\n",
    "    save_file = \"%s/%s_carazolol_hist.pdf\" %(analysis_dir, measurement)\n",
    "    plt.savefig(save_file)\n",
    "    \"\"\"\n",
    "    \n",
    "    for ligand in [\"3p0g_lig\", \"salbutamol\", \"salmeterol\", \"s-carvedilol\", \"isoetharine\", \"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"nebivolol\", \"N-Cyclopentylbutanephrine\"]:\n",
    "        save_file = \"%s/%s_%s_minus_carazolol_frequency.pdf\" %(analysis_dir, measurement, ligand)\n",
    "        if os.path.exists(save_file):\n",
    "            continue\n",
    "            \n",
    "        plt.clf()\n",
    "        print(ligand)\n",
    "        print(measurement)\n",
    "        \n",
    "        kde1 = stats.gaussian_kde(lig_features_eq[ligand][measurement].dropna())\n",
    "        \n",
    "        dc1 = kde1(c)\n",
    "        \n",
    "        plt.plot(c,dc1-dc2)\n",
    "        if ligand == \"3p0g_lig\":\n",
    "            lig_title = \"BI\"\n",
    "        else:\n",
    "            lig_title = ligand\n",
    "        plt.title(\"%s Frequency minus Carazolol Frequency\" %lig_title)\n",
    "        plt.xlabel(\"%s closest heavy atom distance\" %str(measurement))\n",
    "        plt.ylabel(\"Equilibrium Population Change\")\n",
    "        plt.savefig(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jointplot_d3\n",
    "reload(jointplot_d3)\n",
    "from jointplot_d3 import *\n",
    "\n",
    "def custom_lim_finder(values):\n",
    "    mins = np.min(values, axis=0)\n",
    "    maxs = np.max(values, axis=0)\n",
    "    stds = np.std(values, axis=0)\n",
    "    custom_lims = [[mins[i] - 0.5*stds[i], maxs[i] + 0.5*stds[i]] for i in range(0,len(mins))]\n",
    "    return custom_lims\n",
    "\n",
    "#deer_distances = [\"Ala59_Leu266\", \"Thr66_Leu266\", \"Asn148_Leu266\", \"tm6_tm3_dist\", \"rmsd_npxxy_active\"]\n",
    "ligands = [\"3p0g_lig\", \"salbutamol\", \"salmeterol\", \"s-carvedilol\", \"isoetharine\", \"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"nebivolol\", \"N-Cyclopentylbutanephrine\"]\n",
    "deer_distances = [\"tm6_tm3_dist\", \"rmsd_npxxy_active\", \"rmsd_npxxy_inactive\", \"Ala59_Leu266\", \"Thr66_Leu266\", \"Asn148_Leu266\"]\n",
    "#deer_distances = [\"tm6_tm3_dist\", \"rmsd_npxxy_active\"]\n",
    "all_apo_data = lig_features_eq[\"s-carazolol\"][deer_distances].values\n",
    "\n",
    "for ligand in ligands:\n",
    "    jointplots(lig_features_eq[ligand][deer_distances].values, analysis_dir, titles = deer_distances, main = \"%s Minus Carazolol\" %ligand, refcoords = None, refcoords_j=None,\n",
    "            axes=None, reshape=True, data_j=None, titles_j=None, max_tIC=100, min_density=None, \n",
    "            custom_lims=custom_lim_finder(all_apo_data), max_diff=2.5, tpt_paths=None, tpt_paths_j=None,\n",
    "             n_levels=10, worker_pool=None, parallel=True, n_pts=200j, all_apo_data=all_apo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(features_eq[\"rmsd_npxxy_active\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lig_features_eq[\"3p0g_lig\"][measurement].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msm_resampled import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "apo_msm_resampled_file = \"%s/msm_tICs_1_2_3_apo_eq_resampled.h5\"\n",
    "eq_pops = apo_populations\n",
    "msm_apo_populations = np.zeros(len(eq_pops))\n",
    "for cluster_id in bi_msm.mapping_.keys():\n",
    "    msm_apo_populations[bi_msm.mapping_[cluster_id]] = eq_pops[cluster_id]\n",
    "apo_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=apo_msm_resampled_file, equilibrium_populations=msm_apo_populations)\n",
    "apo_pnas_resampled_file = \"%s/msm_tICs_1_2_3_apo_eq_pnas_resampled.h5\"\n",
    "resample_features_by_msm_equilibirum_pop(pnas_coords, apo_traj_to_frames, apo_pnas_resampled_file)\n",
    "jointplots(verboseload(apo_pnas_resampled_file)[::1,:], analysis_dir, titles = pnas_titles, main = \"APO MSM: Canonical Coords\", refcoords_file = None, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2, min_density=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msm_resampled import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "ligand = \"s-carvedilol\"\n",
    "lig_msm_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_resampled.h5\" %(tica_dir, ligand)\n",
    "eq_pops = new_populations[ligand]\n",
    "msm_lig_populations = np.zeros(len(eq_pops))\n",
    "for cluster_id in bi_msm.mapping_.keys():\n",
    "    msm_lig_populations[bi_msm.mapping_[cluster_id]] = eq_pops[cluster_id]\n",
    "lig_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=lig_msm_resampled_file, equilibrium_populations=msm_lig_populations)\n",
    "lig_pnas_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_pnas_resampled.h5\" %(tica_dir, ligand)\n",
    "resample_features_by_msm_equilibirum_pop(pnas_coords, lig_traj_to_frames, lig_pnas_resampled_file)\n",
    "jointplots(verboseload(lig_pnas_resampled_file)[::1,:], analysis_dir, titles = pnas_titles, main = \"%s MSM Canonical Coords\" %ligand, refcoords_file = None, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2,min_density=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from msm_resampled import *\n",
    "total_samples = 100000\n",
    "bi_msm = verboseload(msm_model_dir)\n",
    "clusters_map = clusterer_tICs_1_2_3_map\n",
    "num_trajs = len(get_trajectory_files(traj_dir, traj_ext))\n",
    "ligands = [\"r_epinephrine\"]\n",
    "#ligands = [\"Ici118551\", \"propranolol\", \"s-atenolol\", \"pindolol\", \"nebivolol\", \"s-carvedilol\", \"xamoterol\", \"s-carazolol\", \"3p0g_lig\", \"r_isopreterenol\", \"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"isoetharine\"]\n",
    "for ligand in ligands:\n",
    "    lig_msm_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_resampled.h5\" %(tica_dir, ligand)\n",
    "    eq_pops = new_populations[ligand]\n",
    "    msm_lig_populations = np.zeros(len(eq_pops))\n",
    "    for cluster_id in bi_msm.mapping_.keys():\n",
    "        msm_lig_populations[bi_msm.mapping_[cluster_id]] = eq_pops[cluster_id]\n",
    "    lig_traj_to_frames = resample_by_msm(total_samples, msm_object=bi_msm, clusters_map=clusters_map, num_trajs=num_trajs, save_file=lig_msm_resampled_file, equilibrium_populations=msm_lig_populations)\n",
    "    lig_pnas_resampled_file = \"%s/msm_tICs_1_2_3_%s_eq_pnas_resampled.h5\" %(tica_dir, ligand)\n",
    "    resample_features_by_msm_equilibirum_pop(pnas_coords, lig_traj_to_frames, lig_pnas_resampled_file)\n",
    "    jointplots(verboseload(lig_pnas_resampled_file)[::1,:], analysis_dir, titles = pnas_titles, main = \"%s MSM Canonical Coords\" %ligand, refcoords_file = None, axes=None, data_j=None, titles_j=None, reshape=False, max_tIC=2,min_density=None, custom_xlim=[3,20], custom_ylim=[0,2.])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "\"\"\"\n",
    "samples_tica = pd.read_csv(tica_coords_csv, index_col=0)\n",
    "samples_docking = pd.read_csv(docking_multiple_ligands, index_col=0)\n",
    "common_indices = list(set(samples_docking.index.values).intersection(samples_tica.index.values))\n",
    "samples_tica = samples_tica.loc[common_indices]\n",
    "samples_docking = samples_docking.loc[common_indices]\n",
    "\n",
    "\n",
    "pearson_matrix = np.zeros((samples_docking.shape[1], samples_tica.shape[1]))\n",
    "for i in range(0, pearson_matrix.shape[0]):\n",
    "    for j in range(0, pearson_matrix.shape[1]):\n",
    "        pearson_matrix[i][j] = pearsonr(samples_docking.values[:,i], samples_tica.values[:,j])[0]\n",
    "MI_matrix = np.abs(compute_sr_matrix(samples_docking.values, samples_tica.values))\n",
    "\"\"\"\n",
    "plt.clf()\n",
    "#first_entries = [\"nebivolol\", \"s-carvedilol\", \"s-carazolol\", \"s-atenolol\", \"xamoterol\", \"3p0g_lig\", \"isoetharine\", \"ethylnorepinephrine\", \"salbutamol\", \"norepinephrine\"]\n",
    "secret_compounds = [c for c in delta_delta_g.columns.values if \"Compound\" in c]\n",
    "#drug_order = first_entries + list(set(delta_delta_g.columns.values).difference(set(first_entries)).difference(set(secret_compounds)))\n",
    "#delta_delta_g = delta_delta_g[drug_order]\n",
    "#delta_delta_g.sort(\"nebivolol\", inplace=True)\n",
    "\n",
    "#plot_heatmap(scale(delta_delta_g.values).T, delta_delta_g.columns.values, delta_delta_g.index.values, save_file=\"%s/msm_n-clusters%d_lag-time%d_n-heatmap.pdf\" %(tica_dir, n_clusters, msm_lag_time))\n",
    "#plot_heatmap(MI_matrix, samples_docking.columns.values, samples_tica.columns.values, save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components))\n",
    "ddg_scaled = copy.deepcopy(delta_delta_g)\n",
    "ddg_scaled[delta_delta_g.columns.values] = scale(delta_delta_g.values)\n",
    "#ddg_scaled.index = [n.split(\"cluster\")[1] for n in ddg_scaled.index.values]\n",
    "\n",
    "\n",
    "#plot_clustermap(docking_normalized[[\"nebivolol\", \"terbutaline\", \"s-carvedilol\", \"Ici118551\", \"s-atenolol\", \"propranolol\", \"bisoprolol\", \"s-carazolol\", \"timolol\", \"procaterol\", \"r_isopreterenol\", \"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"isoetharine\", \"N-Cyclopentylbutanephrine\", \"3p0g_lig\", \"fenoterol\", \"formoterol\"]].loc[[\"cluster80\", \"cluster16\", \"cluster99\", \"cluster90\", \"cluster43\", \"cluster62\", \"cluster9\", \"cluster89\", \"cluster58\", \"cluster74\", \"cluster6\"]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='average')\n",
    "#plot_clustermap(ddg_scaled[[\"s-carvedilol\", \"s-carazolol\", \"alprenalol\", \"norepinephrine\", \"nebivolol\", \"clenbuterol\", \"Tulobuterol\", \"r_isopreterenol\", \"isoetharine\", \"formoterol\", \"r_epinephrine\", \"ethylnorepinephrine\", \"N-Cyclopentylbutanephrine\"]].loc[importances_df.index.values.tolist()[:10]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='average')\n",
    "plot_clustermap(ddg_scaled.transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='average')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[importances_df.iloc[0:5].index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_normalized_features_averages_df.iloc[80].subtract(samples_normalized_features_averages_df.iloc[16]).abs().sort(inplace=False, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "all_ligands = [lig for lig in delta_delta_g.columns.values if \"Carv\" not in lig and \"Xam\" not in lig and \"Compound_\" not in lig]\n",
    "X = np.vstack([delta_delta_g[all_ligands].values, ddg_scaled[all_ligands].values]).T\n",
    "y = all_ligands\n",
    "for i in range(0, len(y)):\n",
    "    if \"neb\" in y[i] or \"carv\" in y[i]:\n",
    "        y[i] = \"biased_antagonist\"\n",
    "    else:\n",
    "        y[i] = \"not_biased_antagonist\"\n",
    "y = np.array(y).reshape((-1,1))\n",
    "n_exp = 100\n",
    "importances = []\n",
    "for i in range(0, n_exp):\n",
    "    rfc = RandomForestClassifier(n_estimators=500, max_features='sqrt', n_jobs=-1)\n",
    "    rfc.fit(X,y)\n",
    "    importances.append(rfc.feature_importances_)\n",
    "importances_mu = np.mean(np.array(importances), axis=0)\n",
    "importances_df = pd.DataFrame(importances_mu, index=delta_delta_g.index.values.tolist() + [\"%s_scaled\" %n for n in ddg_scaled.index.values.tolist()], columns=[\"importance\"]).sort(\"importance\", inplace=False, ascending=False)\n",
    "importances_df.iloc[0:20]\n",
    "#X_test = delta_delta_g.loc[delta_delta_g[\"label\"] == 0][[t for t in delta_delta_g.columns.values if t != \"label\"]]\n",
    "#pd.DataFrame(dt.predict(pd.concat([X, X_test])), index=pd.concat([X, X_test]).index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_app = []\n",
    "for n in importances_df.index.values:\n",
    "    if n.split(\"_scaled\")[0] not in first_app:\n",
    "        first_app.append(n)\n",
    "importances_df.loc[first_app].iloc[0:10]\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "importances_df.iloc[0:25].plot(kind='barh', figsize=(4,8))\n",
    "plt.xlabel(\"Average RF Feature Importance\")\n",
    "plt.ylabel(\"MSM State\")\n",
    "plt.title(\"Distinguishing Arrestin Biased Antagonists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "names = [n.split(\"_scaled\")[0] for n in importances_df.index.values.tolist()]\n",
    "new_names = []\n",
    "for n in names:\n",
    "    if n not in new_names: new_names.append(n)\n",
    "plot_clustermap(pd.concat([samples_top_features_avg_df, samples_pnas_avg_df, ddg_scaled[[\"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"r_isopreterenol\", \"nebivolol\", \"s-carvedilol\", \"s-carazolol\", \"s-atenolol\", \"pindolol\", \"propranolol\", 'Ici118551']]],axis=1).loc[new_names[:10]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d_arrestin_biased_antagonist_features.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='single', col_cluster=True, row_cluster=True, ytick_labelsize=8, xtick_labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "rfc = RandomForestClassifier(n_estimators=5000, max_features='sqrt', n_jobs=-1)\n",
    "X = delta_delta_g.values.T\n",
    "y = copy.deepcopy(delta_delta_g.columns.values)\n",
    "for i in range(0, len(y)):\n",
    "    if \"neb\" in y[i] or \"carv\" in y[i]:\n",
    "        y[i] = \"biased_antagonist\"\n",
    "    else:\n",
    "        y[i] = \"not_biased_antagonist\"\n",
    "y = np.array(y).reshape((-1,1))\n",
    "rfc.fit(X,y)\n",
    "importances = pd.DataFrame(rfc.feature_importances_, index=delta_delta_g.index.values, columns=[\"importance\"]).sort(\"importance\", inplace=False, ascending=False)\n",
    "importances.iloc[0:10]\n",
    "#X_test = delta_delta_g.loc[delta_delta_g[\"label\"] == 0][[t for t in delta_delta_g.columns.values if t != \"label\"]]\n",
    "#pd.DataFrame(dt.predict(pd.concat([X, X_test])), index=pd.concat([X, X_test]).index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame(importances, columns=delta_delta_g.index.values.tolist()+[\"%s_scaled\" %n for n in delta_delta_g.index.values.tolist()]).mean(axis=0).transpose().sort(inplace=False, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tica_deltas = pd.concat([pnas_cluster_averages_df, tica_cluster_averages_df, delta_delta_g], axis=1)\n",
    "tica_deltas.iloc[list(biased_antagonist_indices)].sort(\"s-carvedilol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_docking_dir = \"/home/enf/b2ar_analysis/reference_docking/docking_SP\"\n",
    "reference_ligand_docking = \"%s/all_docking_scores.csv\" % reference_docking_dir\n",
    "\n",
    "#analyze_docking_results_multiple(reference_docking_dir, precision = \"SP\", ligands = biased_ligands + agonist_ligands + inverse_ligands, summary = reference_ligand_docking , redo = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reference_docking = pd.read_csv(reference_ligand_docking, index_col=0).dropna()\n",
    "reference_docking.columns = [''.join(e for e in lig if e.isalnum() or e=='-' or e=='_') for lig in reference_docking.columns.values]\n",
    "reference_docking.loc[\"null_scores\"] = reference_docking.iloc[1].subtract(reference_docking.iloc[0])                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler\n",
    "\n",
    "features = delta_delta_g.transpose()\n",
    "null_features = reference_docking.transpose().loc[features.index]\n",
    "\n",
    "classes = pd.read_csv(\"/home/enf/b2ar_analysis/b2ar_antagonists_agonists3.csv\", header=None)\n",
    "\n",
    "agonists = classes.iloc[1].dropna().values.tolist()\n",
    "agonists = [''.join(e for e in lig if e.isalnum() or e=='-' or e=='_') for lig in agonists]\n",
    "\n",
    "antagonists = classes.iloc[0].dropna().values.tolist()\n",
    "antagonists = [''.join(e for e in lig if e.isalnum() or e=='-' or e=='_') for lig in antagonists]\n",
    "\n",
    "\n",
    "labels = np.zeros((features.shape[0], 1), dtype=object)\n",
    "for agonist in agonists:\n",
    "    try:\n",
    "        labels[features.index.values.tolist().index(agonist), 0] = \"agonist\"\n",
    "    except:\n",
    "        print(agonist)\n",
    "        continue\n",
    "for agonist in antagonists:\n",
    "    try:\n",
    "        labels[features.index.values.tolist().index(agonist), 0] = \"antagonist\"\n",
    "    except:\n",
    "        print(agonist)\n",
    "        continue\n",
    "non_zero_inds = np.where(labels != 0)[0]\n",
    "X = features.values[non_zero_inds,:]\n",
    "N = null_features.values[non_zero_inds,2]\n",
    "C = N\n",
    "y = labels[non_zero_inds, :]\n",
    "y = label_binarize(y, [\"agonist\", \"antagonist\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "test_accuracies = []\n",
    "test_r2s = []\n",
    "C_test_accuracies = []\n",
    "C_test_r2s = []\n",
    "n_trials = 25\n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    n_exp = 1\n",
    "    accuracies = []\n",
    "    r2s = []\n",
    "    importances = []\n",
    "\n",
    "    gbr_accuracies = []\n",
    "    gbr_r2s = []\n",
    "    gbr_importances = []\n",
    "\n",
    "    oob_scores = []\n",
    "\n",
    "    C_accuracies = []\n",
    "    C_r2s = []\n",
    "    C_importances = []\n",
    "    C_oob_scores = []\n",
    "\n",
    "    X = delta_delta_g[common_ligands].values.T\n",
    "    C = null_features.loc[common_ligands].values\n",
    "    y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    #X_train = np.hstack([X_train, sc.transform(X_train)])\n",
    "    #X_test = np.hstack([X_test, sc.transform(X_test)])\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    C_train = sc.transform(C_train)\n",
    "    C_test = sc.transform(C_test)\n",
    "    #C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "    #C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train,y_train)\n",
    "    top_features = np.argsort(-1.0*rfr.feature_importances_)[0:5]\n",
    "    print(top_features)\n",
    "    \n",
    "    X_train = X_train[:, top_features]\n",
    "    X_test = X_test[:, top_features]\n",
    "    a\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    test_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "    test_r2s.append(r2_score(y_test, rfr.predict(X_test)))\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train, y_train)\n",
    "    C_test_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(C_test).reshape((-1,1))))))\n",
    "    C_test_r2s.append(r2_score(y_test, rfr.predict(C_test)))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(test_r2s))\n",
    "print(np.median(C_test_r2s))\n",
    "print(np.median(test_accuracies))\n",
    "print(np.median(C_test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "test_accuracies = []\n",
    "test_r2s = []\n",
    "C_test_accuracies = []\n",
    "C_test_r2s = []\n",
    "n_trials = 25\n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    print(j)\n",
    "    n_exp = 1\n",
    "    accuracies = []\n",
    "    r2s = []\n",
    "    importances = []\n",
    "\n",
    "    gbr_accuracies = []\n",
    "    gbr_r2s = []\n",
    "    gbr_importances = []\n",
    "\n",
    "    oob_scores = []\n",
    "\n",
    "    C_accuracies = []\n",
    "    C_r2s = []\n",
    "    C_importances = []\n",
    "    C_oob_scores = []\n",
    "\n",
    "    X = delta_delta_g[common_ligands].values.T\n",
    "    C = null_features.loc[common_ligands].values\n",
    "    y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    #X_train = sc.transform(X_train)\n",
    "    #X_test = sc.transform(X_test)\n",
    "    X_train = np.hstack([X_train, sc.transform(X_train)])\n",
    "    X_test = np.hstack([X_test, sc.transform(X_test)])\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    #C_train = sc.transform(C_train)\n",
    "    #C_test = sc.transform(C_test)\n",
    "    C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "    C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "    \n",
    "    train_importances = []\n",
    "    random_splits = 25\n",
    "    for k in range(0, random_splits):\n",
    "        rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "        rfr.fit(X_train, y_train)\n",
    "        train_importances.append(rfr.feature_importances_)\n",
    "        \n",
    "    train_importances = np.mean(np.vstack(train_importances), axis=0)\n",
    "    top_features = np.argsort(-1.0*train_importances)[0:10]\n",
    "    X_train = np.hstack([X_train[:, top_features], C_train])\n",
    "    X_test = np.hstack([X_test[:, top_features], C_test])\n",
    "\n",
    "    #rfr = GradientBoostingRegressor(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    test_accuracies.append(np.sqrt(np.mean(np.square(y_test-y_pred.reshape((-1,1))))))\n",
    "    test_r2s.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "\n",
    "    \n",
    "    #rfr = GradientBoostingRegressor(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train, y_train)\n",
    "    C_y_pred = rfr.predict(C_test)\n",
    "    C_test_accuracies.append(np.sqrt(np.mean(np.square(y_test-C_y_pred.reshape((-1,1))))))\n",
    "    C_test_r2s.append(r2_score(y_test, C_y_pred))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "\n",
    "test_accuracies = []\n",
    "test_r2s = []\n",
    "C_test_accuracies = []\n",
    "C_test_r2s = []\n",
    "coefs = []\n",
    "n_trials = 10\n",
    "\n",
    "X = delta_delta_g[common_ligands].values.T\n",
    "C = null_features.loc[common_ligands].values\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values\n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    n_exp = 1\n",
    "\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    C_train = sc.transform(C_train)\n",
    "    C_test = sc.transform(C_test)\n",
    "    #C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "    #C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "    \n",
    "        \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    #X_train = np.hstack([X_train, sc.transform(X_train)])#, C_train])\n",
    "    #X_test = np.hstack([X_test, sc.transform(X_test)])#, C_test])\n",
    "    \n",
    "    rfr = LassoCV(n_jobs=-1, cv=10, fit_intercept=False, alphas=np.logspace(0.00001,1.0,1000))\n",
    "    #rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(np.hstack([X_train, C_train]), y_train)\n",
    "    coefs.append(rfr.coef_)\n",
    "    #y_pred = rfr.predict(X_test)\n",
    "    #test_accuracies.append(np.sqrt(np.mean(np.square(y_test-y_pred.reshape((-1,1))))))\n",
    "    #test_r2s.append(r2_score(y_test, y_pred))\n",
    "    test_r2s.append(rfr.score(np.hstack([X_test, C_test]), y_test))\n",
    "\n",
    "    \n",
    "    #rfr = LinearRegression(fit_intercept=False)\n",
    "    #rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    #rfr.fit(C_train, y_train)\n",
    "    #C_y_pred = rfr.predict(C_test)\n",
    "    #C_test_accuracies.append(np.sqrt(np.mean(np.square(y_test-C_y_pred.reshape((-1,1))))))\n",
    "    #C_test_r2s.append(rfr.score(C_test, y_test))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(test_r2s))\n",
    "print(np.median(C_test_r2s))\n",
    "print(np.median(test_accuracies))\n",
    "print(np.median(C_test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances_df = make_importances_df(coefs, delta_delta_g.index.values.tolist())\n",
    "#importances_df.loc[[\"cluster80\", \"cluster80_scaled\"]]\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster89\t0.045510\n",
    "cluster16\t0.045213\n",
    "cluster16_scaled\t0.030536\n",
    "cluster58\t0.023098\n",
    "cluster80\t0.022688\n",
    "cluster83\t0.021890\n",
    "cluster80_scaled\t0.021453\n",
    "cluster62_scaled\t0.020681\n",
    "cluster74_scaled\t0.016951\n",
    "cluster89_scaled\t0.016909\n",
    "cluster36\t0.015715\n",
    "cluster74\t0.015292\n",
    "cluster83_scaled\t0.015117\n",
    "cluster69_scaled\t0.014170\n",
    "cluster62\t0.013974\n",
    "cluster61_scaled\t0.013855\n",
    "cluster91_scaled\t0.013455\n",
    "cluster51\t0.013423\n",
    "cluster36_scaled\t0.013396\n",
    "cluster67\t0.013267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def b(x, y, i):\n",
    "    return y[i+1] - x[i+1] * (y[i+1] - y[i]) / (x[i+1] - x[i])\n",
    "\n",
    "def logauc(x, y, lam=0.001):\n",
    "    num = 0.\n",
    "    for i in range(0, len(x)-1):\n",
    "        if x[i] >= lam:\n",
    "            num += ((y[i+1]-y[i])/np.log(10) + b(x, y, i) * (np.log10(x[i+1]) - np.log10(x[i])))\n",
    "    return num / (np.log10(1./lam))\n",
    "\n",
    "def logauc2(x, y, lam=0.001):\n",
    "    num = 0.\n",
    "    for i in range(0, len(x)-1):\n",
    "        if x[i] >= lam:\n",
    "            num += (np.log10(x[i+1]) - np.log10(x[i])) * (y[i+1]+y[i]) /2.\n",
    "    return num / (np.log10(1./lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Name</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>B2AR-Gprotein, Mean</th>\n",
       "      <th>B2AR-Gprotein, IA(from CR curves) Mean</th>\n",
       "      <th>B2AR-Arrestin, Mean</th>\n",
       "      <th>B2AR-Arrestin, IA(from CR curves) Mean</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EvanName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adrenalone</th>\n",
       "      <td>1</td>\n",
       "      <td>Adrenalone</td>\n",
       "      <td>ADO</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salbutamol</th>\n",
       "      <td>4</td>\n",
       "      <td>Albuterol (Salbutamol)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alprenalol</th>\n",
       "      <td>5</td>\n",
       "      <td>Alprenolol</td>\n",
       "      <td>ALP</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s-atenolol</th>\n",
       "      <td>6</td>\n",
       "      <td>Atenolol</td>\n",
       "      <td>ATE</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bisoprolol</th>\n",
       "      <td>7</td>\n",
       "      <td>Bisoprolol</td>\n",
       "      <td>BIS</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tulobuterol</th>\n",
       "      <td>9</td>\n",
       "      <td>C78 (Tulobuterol)</td>\n",
       "      <td>C78</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carvedilol</th>\n",
       "      <td>10</td>\n",
       "      <td>Carvedilol</td>\n",
       "      <td>CARV</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cgp12177</th>\n",
       "      <td>11</td>\n",
       "      <td>CGP 12177</td>\n",
       "      <td>CGP</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cimaterol</th>\n",
       "      <td>12</td>\n",
       "      <td>Cimeterol</td>\n",
       "      <td>CIM</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clenbuterol</th>\n",
       "      <td>13</td>\n",
       "      <td>Clenbuterol</td>\n",
       "      <td>CLEN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dichloroisopreterenol</th>\n",
       "      <td>14</td>\n",
       "      <td>Dichloroisoproterenol</td>\n",
       "      <td>DCI</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dobutamine</th>\n",
       "      <td>15</td>\n",
       "      <td>Dobutamine</td>\n",
       "      <td>DOB</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dopamine</th>\n",
       "      <td>16</td>\n",
       "      <td>Dopamine</td>\n",
       "      <td>DOP</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du211117</th>\n",
       "      <td>17</td>\n",
       "      <td>Du 21117</td>\n",
       "      <td>DU21</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du28663</th>\n",
       "      <td>18</td>\n",
       "      <td>Du 28663</td>\n",
       "      <td>DU28</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_epinephrine</th>\n",
       "      <td>19</td>\n",
       "      <td>Epinephrine</td>\n",
       "      <td>EPI</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fenoterol</th>\n",
       "      <td>20</td>\n",
       "      <td>Fenoterol</td>\n",
       "      <td>FEN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hexoprenaline</th>\n",
       "      <td>21</td>\n",
       "      <td>Hexoprenaline</td>\n",
       "      <td>HEX</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ici118551</th>\n",
       "      <td>22</td>\n",
       "      <td>ICI 118551</td>\n",
       "      <td>ICI118</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ici215001</th>\n",
       "      <td>23</td>\n",
       "      <td>ICI 215001</td>\n",
       "      <td>ICI215</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ici89406</th>\n",
       "      <td>24</td>\n",
       "      <td>ICI 89406</td>\n",
       "      <td>ICI89</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isopropylnorsynephrine</th>\n",
       "      <td>25</td>\n",
       "      <td>Isopropylnorsynephrine</td>\n",
       "      <td>IPNS</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_isopreterenol</th>\n",
       "      <td>26</td>\n",
       "      <td>Isoproterenol</td>\n",
       "      <td>ISO</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labetalol</th>\n",
       "      <td>27</td>\n",
       "      <td>Labetalol</td>\n",
       "      <td>LAB</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>28</td>\n",
       "      <td>MAPE [2-(methylamino)-1-\\rphenylethanol]\\rhalo...</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clenproperol</th>\n",
       "      <td>29</td>\n",
       "      <td>NAB 277 (clenproperol)</td>\n",
       "      <td>NAB27</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinine</th>\n",
       "      <td>30</td>\n",
       "      <td>N-methyl-dopamine (epinine)</td>\n",
       "      <td>NMDOP</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norepinephrine</th>\n",
       "      <td>31</td>\n",
       "      <td>Norepinephrine</td>\n",
       "      <td>NREPI</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nor-metanephrine</th>\n",
       "      <td>32</td>\n",
       "      <td>Nor-metanephrine</td>\n",
       "      <td>NRMET</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orciprenaline</th>\n",
       "      <td>33</td>\n",
       "      <td>Orciprenaline (alupent)</td>\n",
       "      <td>ORCI</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pindolol</th>\n",
       "      <td>34</td>\n",
       "      <td>Pindolol</td>\n",
       "      <td>PIN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>practolol</th>\n",
       "      <td>35</td>\n",
       "      <td>Practolol</td>\n",
       "      <td>PRAC</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronethalol</th>\n",
       "      <td>36</td>\n",
       "      <td>Pronethalol</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propranolol</th>\n",
       "      <td>37</td>\n",
       "      <td>Propranolol</td>\n",
       "      <td>PROP</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ritrodine</th>\n",
       "      <td>38</td>\n",
       "      <td>Ritodrine</td>\n",
       "      <td>RIT</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skf42469</th>\n",
       "      <td>39</td>\n",
       "      <td>SKF 42469</td>\n",
       "      <td>SKF42</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sotalol</th>\n",
       "      <td>40</td>\n",
       "      <td>Sotalol (betapace)</td>\n",
       "      <td>SOT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulfonterol</th>\n",
       "      <td>41</td>\n",
       "      <td>Sulfonterol</td>\n",
       "      <td>SULF</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terbutaline</th>\n",
       "      <td>42</td>\n",
       "      <td>Terbutaline</td>\n",
       "      <td>TERB</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TERBSN</th>\n",
       "      <td>43</td>\n",
       "      <td>Tertbutylnorsynephrine</td>\n",
       "      <td>TERBSN</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timolol</th>\n",
       "      <td>44</td>\n",
       "      <td>Timolol</td>\n",
       "      <td>TIM</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xamoterol</th>\n",
       "      <td>45</td>\n",
       "      <td>Xamoterol (ICI 118587)</td>\n",
       "      <td>XAM</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Number  \\\n",
       "EvanName                         \n",
       "adrenalone                   1   \n",
       "salbutamol                   4   \n",
       "alprenalol                   5   \n",
       "s-atenolol                   6   \n",
       "bisoprolol                   7   \n",
       "Tulobuterol                  9   \n",
       "Carvedilol                  10   \n",
       "cgp12177                    11   \n",
       "cimaterol                   12   \n",
       "clenbuterol                 13   \n",
       "dichloroisopreterenol       14   \n",
       "dobutamine                  15   \n",
       "dopamine                    16   \n",
       "du211117                    17   \n",
       "du28663                     18   \n",
       "r_epinephrine               19   \n",
       "fenoterol                   20   \n",
       "hexoprenaline               21   \n",
       "Ici118551                   22   \n",
       "Ici215001                   23   \n",
       "Ici89406                    24   \n",
       "isopropylnorsynephrine      25   \n",
       "r_isopreterenol             26   \n",
       "labetalol                   27   \n",
       "MAPE                        28   \n",
       "clenproperol                29   \n",
       "epinine                     30   \n",
       "norepinephrine              31   \n",
       "nor-metanephrine            32   \n",
       "orciprenaline               33   \n",
       "pindolol                    34   \n",
       "practolol                   35   \n",
       "pronethalol                 36   \n",
       "propranolol                 37   \n",
       "ritrodine                   38   \n",
       "skf42469                    39   \n",
       "sotalol                     40   \n",
       "sulfonterol                 41   \n",
       "terbutaline                 42   \n",
       "TERBSN                      43   \n",
       "timolol                     44   \n",
       "xamoterol                   45   \n",
       "\n",
       "                                                                     Name  \\\n",
       "EvanName                                                                    \n",
       "adrenalone                                                     Adrenalone   \n",
       "salbutamol                                         Albuterol (Salbutamol)   \n",
       "alprenalol                                                     Alprenolol   \n",
       "s-atenolol                                                       Atenolol   \n",
       "bisoprolol                                                     Bisoprolol   \n",
       "Tulobuterol                                             C78 (Tulobuterol)   \n",
       "Carvedilol                                                     Carvedilol   \n",
       "cgp12177                                                        CGP 12177   \n",
       "cimaterol                                                       Cimeterol   \n",
       "clenbuterol                                                   Clenbuterol   \n",
       "dichloroisopreterenol                               Dichloroisoproterenol   \n",
       "dobutamine                                                     Dobutamine   \n",
       "dopamine                                                         Dopamine   \n",
       "du211117                                                         Du 21117   \n",
       "du28663                                                          Du 28663   \n",
       "r_epinephrine                                                 Epinephrine   \n",
       "fenoterol                                                       Fenoterol   \n",
       "hexoprenaline                                               Hexoprenaline   \n",
       "Ici118551                                                      ICI 118551   \n",
       "Ici215001                                                      ICI 215001   \n",
       "Ici89406                                                        ICI 89406   \n",
       "isopropylnorsynephrine                             Isopropylnorsynephrine   \n",
       "r_isopreterenol                                             Isoproterenol   \n",
       "labetalol                                                       Labetalol   \n",
       "MAPE                    MAPE [2-(methylamino)-1-\\rphenylethanol]\\rhalo...   \n",
       "clenproperol                                       NAB 277 (clenproperol)   \n",
       "epinine                                       N-methyl-dopamine (epinine)   \n",
       "norepinephrine                                             Norepinephrine   \n",
       "nor-metanephrine                                         Nor-metanephrine   \n",
       "orciprenaline                                     Orciprenaline (alupent)   \n",
       "pindolol                                                         Pindolol   \n",
       "practolol                                                       Practolol   \n",
       "pronethalol                                                   Pronethalol   \n",
       "propranolol                                                   Propranolol   \n",
       "ritrodine                                                       Ritodrine   \n",
       "skf42469                                                        SKF 42469   \n",
       "sotalol                                                Sotalol (betapace)   \n",
       "sulfonterol                                                   Sulfonterol   \n",
       "terbutaline                                                   Terbutaline   \n",
       "TERBSN                                             Tertbutylnorsynephrine   \n",
       "timolol                                                           Timolol   \n",
       "xamoterol                                          Xamoterol (ICI 118587)   \n",
       "\n",
       "                       Abbreviation  B2AR-Gprotein, Mean  \\\n",
       "EvanName                                                   \n",
       "adrenalone                      ADO                 1.01   \n",
       "salbutamol                      ALB                 0.81   \n",
       "alprenalol                      ALP                 0.05   \n",
       "s-atenolol                      ATE                 0.03   \n",
       "bisoprolol                      BIS                -0.03   \n",
       "Tulobuterol                     C78                 0.47   \n",
       "Carvedilol                     CARV                -0.01   \n",
       "cgp12177                        CGP                 0.00   \n",
       "cimaterol                       CIM                 0.93   \n",
       "clenbuterol                    CLEN                 0.51   \n",
       "dichloroisopreterenol           DCI                 0.19   \n",
       "dobutamine                      DOB                 0.63   \n",
       "dopamine                        DOP                 0.66   \n",
       "du211117                       DU21                 1.02   \n",
       "du28663                        DU28                 1.09   \n",
       "r_epinephrine                   EPI                 1.00   \n",
       "fenoterol                       FEN                 0.91   \n",
       "hexoprenaline                   HEX                 1.22   \n",
       "Ici118551                    ICI118                -0.06   \n",
       "Ici215001                    ICI215                -0.03   \n",
       "Ici89406                      ICI89                 0.03   \n",
       "isopropylnorsynephrine         IPNS                 0.57   \n",
       "r_isopreterenol                 ISO                 0.96   \n",
       "labetalol                       LAB                 0.06   \n",
       "MAPE                           MAPE                 0.56   \n",
       "clenproperol                  NAB27                 0.64   \n",
       "epinine                       NMDOP                 0.92   \n",
       "norepinephrine                NREPI                 0.99   \n",
       "nor-metanephrine              NRMET                 0.24   \n",
       "orciprenaline                  ORCI                 0.84   \n",
       "pindolol                        PIN                 0.00   \n",
       "practolol                      PRAC                 0.02   \n",
       "pronethalol                    PRON                 0.00   \n",
       "propranolol                    PROP                -0.01   \n",
       "ritrodine                       RIT                 0.77   \n",
       "skf42469                      SKF42                 0.97   \n",
       "sotalol                         SOT                 0.00   \n",
       "sulfonterol                    SULF                 0.40   \n",
       "terbutaline                    TERB                 0.80   \n",
       "TERBSN                       TERBSN                 0.58   \n",
       "timolol                         TIM                -0.03   \n",
       "xamoterol                       XAM                 0.13   \n",
       "\n",
       "                       B2AR-Gprotein, IA(from CR curves) Mean  \\\n",
       "EvanName                                                        \n",
       "adrenalone                                               1.00   \n",
       "salbutamol                                               0.64   \n",
       "alprenalol                                                  -   \n",
       "s-atenolol                                                  -   \n",
       "bisoprolol                                                  -   \n",
       "Tulobuterol                                              0.36   \n",
       "Carvedilol                                                  -   \n",
       "cgp12177                                                    -   \n",
       "cimaterol                                                0.81   \n",
       "clenbuterol                                              0.49   \n",
       "dichloroisopreterenol                                    0.24   \n",
       "dobutamine                                               0.56   \n",
       "dopamine                                                 0.72   \n",
       "du211117                                                 0.87   \n",
       "du28663                                                  0.79   \n",
       "r_epinephrine                                            1.00   \n",
       "fenoterol                                                0.77   \n",
       "hexoprenaline                                            0.81   \n",
       "Ici118551                                                   -   \n",
       "Ici215001                                                   -   \n",
       "Ici89406                                                    -   \n",
       "isopropylnorsynephrine                                   0.52   \n",
       "r_isopreterenol                                          1.00   \n",
       "labetalol                                                   -   \n",
       "MAPE                                                     0.59   \n",
       "clenproperol                                             0.54   \n",
       "epinine                                                  0.91   \n",
       "norepinephrine                                           1.01   \n",
       "nor-metanephrine                                            -   \n",
       "orciprenaline                                            0.76   \n",
       "pindolol                                                    -   \n",
       "practolol                                                   -   \n",
       "pronethalol                                                 -   \n",
       "propranolol                                                 -   \n",
       "ritrodine                                                0.53   \n",
       "skf42469                                                 0.83   \n",
       "sotalol                                                     -   \n",
       "sulfonterol                                              0.33   \n",
       "terbutaline                                              0.79   \n",
       "TERBSN                                                   0.45   \n",
       "timolol                                                     -   \n",
       "xamoterol                                                0.21   \n",
       "\n",
       "                        B2AR-Arrestin, Mean  \\\n",
       "EvanName                                      \n",
       "adrenalone                             0.95   \n",
       "salbutamol                             0.29   \n",
       "alprenalol                             0.00   \n",
       "s-atenolol                             0.00   \n",
       "bisoprolol                             0.00   \n",
       "Tulobuterol                            0.03   \n",
       "Carvedilol                             0.00   \n",
       "cgp12177                               0.00   \n",
       "cimaterol                              0.63   \n",
       "clenbuterol                            0.13   \n",
       "dichloroisopreterenol                  0.00   \n",
       "dobutamine                             0.02   \n",
       "dopamine                               0.04   \n",
       "du211117                               0.63   \n",
       "du28663                                0.63   \n",
       "r_epinephrine                          1.00   \n",
       "fenoterol                              0.96   \n",
       "hexoprenaline                          1.16   \n",
       "Ici118551                              0.00   \n",
       "Ici215001                              0.00   \n",
       "Ici89406                               0.00   \n",
       "isopropylnorsynephrine                 0.02   \n",
       "r_isopreterenol                        0.96   \n",
       "labetalol                              0.00   \n",
       "MAPE                                   0.02   \n",
       "clenproperol                           0.10   \n",
       "epinine                                0.89   \n",
       "norepinephrine                         0.87   \n",
       "nor-metanephrine                       0.00   \n",
       "orciprenaline                          0.41   \n",
       "pindolol                               0.00   \n",
       "practolol                              0.00   \n",
       "pronethalol                            0.00   \n",
       "propranolol                            0.00   \n",
       "ritrodine                              0.04   \n",
       "skf42469                               0.88   \n",
       "sotalol                                0.00   \n",
       "sulfonterol                            0.01   \n",
       "terbutaline                            0.47   \n",
       "TERBSN                                 0.02   \n",
       "timolol                                0.00   \n",
       "xamoterol                              0.00   \n",
       "\n",
       "                       B2AR-Arrestin, IA(from CR curves) Mean  Unnamed: 8  \n",
       "EvanName                                                                   \n",
       "adrenalone                                               0.94       -0.06  \n",
       "salbutamol                                               0.31       -0.52  \n",
       "alprenalol                                                  -       -0.05  \n",
       "s-atenolol                                                  -       -0.03  \n",
       "bisoprolol                                                  -        0.03  \n",
       "Tulobuterol                                                 -       -0.44  \n",
       "Carvedilol                                                  -        0.01  \n",
       "cgp12177                                                    -        0.00  \n",
       "cimaterol                                                0.46       -0.30  \n",
       "clenbuterol                                              0.15       -0.38  \n",
       "dichloroisopreterenol                                       -       -0.19  \n",
       "dobutamine                                                  -       -0.61  \n",
       "dopamine                                                    -       -0.62  \n",
       "du211117                                                 0.62       -0.39  \n",
       "du28663                                                  0.57       -0.46  \n",
       "r_epinephrine                                               1        0.00  \n",
       "fenoterol                                                0.75        0.05  \n",
       "hexoprenaline                                            0.89       -0.06  \n",
       "Ici118551                                                   -        0.06  \n",
       "Ici215001                                                   -        0.03  \n",
       "Ici89406                                                    -       -0.03  \n",
       "isopropylnorsynephrine                                      -       -0.55  \n",
       "r_isopreterenol                                          0.94        0.00  \n",
       "labetalol                                                   -       -0.06  \n",
       "MAPE                                                        -       -0.54  \n",
       "clenproperol                                             0.14       -0.54  \n",
       "epinine                                                   0.9       -0.03  \n",
       "norepinephrine                                           0.84       -0.12  \n",
       "nor-metanephrine                                            -       -0.24  \n",
       "orciprenaline                                             0.4       -0.43  \n",
       "pindolol                                                    -        0.00  \n",
       "practolol                                                   -       -0.02  \n",
       "pronethalol                                                 -        0.00  \n",
       "propranolol                                                 -        0.01  \n",
       "ritrodine                                                   -       -0.73  \n",
       "skf42469                                                 0.77       -0.09  \n",
       "sotalol                                                     -        0.00  \n",
       "sulfonterol                                                 -       -0.39  \n",
       "terbutaline                                              0.41       -0.33  \n",
       "TERBSN                                                      -       -0.56  \n",
       "timolol                                                     -        0.03  \n",
       "xamoterol                                                   -       -0.13  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bret = pd.read_csv(\"/home/enf/b2ar_analysis/bias_analysis/bret_bias_study.csv\", header=0).dropna().set_index(\"EvanName\")\n",
    "bret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvanName\n",
       "ritrodine                -0.73\n",
       "dopamine                 -0.62\n",
       "dobutamine               -0.61\n",
       "TERBSN                   -0.56\n",
       "isopropylnorsynephrine   -0.55\n",
       "clenproperol             -0.54\n",
       "MAPE                     -0.54\n",
       "salbutamol               -0.52\n",
       "du28663                  -0.46\n",
       "Tulobuterol              -0.44\n",
       "orciprenaline            -0.43\n",
       "sulfonterol              -0.39\n",
       "du211117                 -0.39\n",
       "clenbuterol              -0.38\n",
       "terbutaline              -0.33\n",
       "cimaterol                -0.30\n",
       "nor-metanephrine         -0.24\n",
       "dichloroisopreterenol    -0.19\n",
       "xamoterol                -0.13\n",
       "norepinephrine           -0.12\n",
       "skf42469                 -0.09\n",
       "adrenalone               -0.06\n",
       "hexoprenaline            -0.06\n",
       "labetalol                -0.06\n",
       "alprenalol               -0.05\n",
       "epinine                  -0.03\n",
       "Ici89406                 -0.03\n",
       "s-atenolol               -0.03\n",
       "practolol                -0.02\n",
       "r_epinephrine             0.00\n",
       "pindolol                  0.00\n",
       "pronethalol               0.00\n",
       "cgp12177                  0.00\n",
       "sotalol                   0.00\n",
       "r_isopreterenol           0.00\n",
       "propranolol               0.01\n",
       "Carvedilol                0.01\n",
       "timolol                   0.03\n",
       "bisoprolol                0.03\n",
       "Ici215001                 0.03\n",
       "fenoterol                 0.05\n",
       "Ici118551                 0.06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bret[\"B2AR-Arrestin, Mean\"].subtract(bret[\"B2AR-Gprotein, Mean\"]).sort(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_ligands = [n for n in bret.index.values if n in delta_delta_g.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc as calculate_auc\n",
    "def compute_auc(y_train, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_train, y_score[:,1])\n",
    "    roc_auc = calculate_auc(fpr, tpr)\n",
    "    log_auc = logauc2(fpr, tpr)\n",
    "    return roc_auc, log_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_classification_experiment(features, y, feature_names, n_trials, train_size=0.8, regularize=False):\n",
    "    test_accuracies = []\n",
    "    test_aucs = []\n",
    "    test_log_aucs = []\n",
    "    C_test_aucs = []\n",
    "    C_test_log_aucs = []\n",
    "    feature_importances = []\n",
    "\n",
    "    features_y = copy.deepcopy(features)\n",
    "    features_y.append(y)\n",
    "    \n",
    "    for j in range(0,n_trials):\n",
    "        print(j)\n",
    "        aucs = []\n",
    "        log_aucs = []\n",
    "        train_test_arrays = sklearn.cross_validation.train_test_split(*features_y, train_size=0.8, stratify=y) \n",
    "        y_train = train_test_arrays[2*len(features)]\n",
    "        y_test = train_test_arrays[2*len(features) + 1]\n",
    "        feature_importance = []\n",
    "\n",
    "        for i in range(0, len(features)):\n",
    "            X_train = train_test_arrays[2*i]\n",
    "            X_test = train_test_arrays[2*i+1]\n",
    "\n",
    "            sc = StandardScaler()\n",
    "            sc.fit(X_train)\n",
    "            X_train = sc.transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "\n",
    "            rfr = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=3, n_jobs=-1, oob_score=True)\n",
    "            rfr.fit(X_train, y_train)\n",
    "            if not regularize:\n",
    "                feature_importance.append(rfr.feature_importances_)\n",
    "            else:\n",
    "                top_indices = np.argsort(rfr.feature_importances_*-1.)[:min(10, X.shape[1])]\n",
    "                rfr = RandomForestClassifier(n_estimators=10, max_features=None, n_jobs=-1, oob_score=True)\n",
    "                X_train = X_train[:, top_indices]\n",
    "                X_test = X_test[:, top_indices]\n",
    "                rfr.fit(X_train, y_train)\n",
    "                f = np.zeros(X.shape[1])\n",
    "                f[top_indices] = rfr.feature_importances_\n",
    "                feature_importance.append(f)\n",
    "\n",
    "\n",
    "\n",
    "            if train_size == 1.:\n",
    "                X_test = X_train\n",
    "                y_test = y_train\n",
    "            \n",
    "            y_pred = rfr.predict(X_test)\n",
    "            y_score = rfr.predict_proba(X_test)\n",
    "            auc, logauc = compute_auc(y_test, y_score)\n",
    "            aucs.append(auc)\n",
    "            log_aucs.append(logauc)  \n",
    "        feature_importances.append(feature_importance)\n",
    "        test_aucs.append(aucs)\n",
    "        test_log_aucs.append(log_aucs)\n",
    "    \n",
    "    return test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gprot_results = copy.deepcopy([test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances])\n",
    "import pickle\n",
    "with open(\"%s/gprot_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gprot_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrestin_results = copy.deepcopy([test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances])\n",
    "import pickle\n",
    "with open(\"%s/arrestin_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(arrestin_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrestin_vs_gprot_results = copy.deepcopy([test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances])\n",
    "import pickle\n",
    "with open(\"%s/arrestin_vs_gprot_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(arrestin_vs_gprot_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances = arrestin_vs_gprot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gprotein_results = copy.deepcopy([test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#arrestin_antagonists = [\"s-carvedilol\", \"nebivolol\"]\n",
    "#non_arrestin_antagonists = [n for n in antagonists if n not in arrestin_antagonists and n not in [\"Carvedilol\"]]\n",
    "#y = np.array([1. for i in arrestin_antagonists] + [0. for i in non_arrestin_antagonists]).reshape((-1,1))\n",
    "\n",
    "\n",
    "#total_activity = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].add(bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands])\n",
    "#common_agonists = arrestin_antagonists + non_arrestin_antagonists\n",
    "#biased_ligands = [\"ethylnorepinephrine\", \"isoetharine\", \"N-Cyclopentylbutanephrine\"]\n",
    "#non_biased_ligands =  [\"r_isopreterenol\", \"r_epinephrine\", \"norepinephrine\", \"zinterol\", \"orciprenaline\", \"epinine\", \"terbutaline\", \"fenoterol\", \"procaterol\", \"formoterol\", \"salbutamol\", \"salmeterol\"]\n",
    "#y = np.array([1. for i in biased_ligands] + [0. for i in non_biased_ligands]).reshape((-1,1))\n",
    "#common_agonists = biased_ligands + non_biased_ligands\n",
    "\n",
    "#common_agonists = total_activity.loc[total_activity > 0.2].index.values\n",
    "#y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].subtract(bret[\"B2AR-Gprotein, Mean\"].loc[common_agonists]).values.reshape((-1,1))\n",
    "\n",
    "top_clusters = delta_delta_g.index.values\n",
    "#top_clusters = list(set(delta_delta_g.sort(\"nebivolol\").index.values[:10].tolist() + delta_delta_g.sort(\"3p0g_lig\").index.values[:10].tolist()))\n",
    "#top_clusters = list(set(delta_delta_g.sort(\"N-Cyclopentylbutanephrine\", inplace=False).index.values[:4].tolist() + delta_delta_g.sort(\"procaterol\", inplace=False).index.values[:4].tolist()))\n",
    "#agonists_df = [a for a in agonists if a in delta_delta_g.columns.values]\n",
    "#common_agonists = agonists_df + antagonists\n",
    "#y = np.array([1. for i in agonists_df] + [0. for i in antagonists]).reshape((-1,1))\n",
    "common_agonists = common_ligands\n",
    "y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].values.reshape((-1,1))\n",
    "y = binarize(y_ori, threshold=0.2)\n",
    "\n",
    "X = delta_delta_g.loc[top_clusters][common_agonists].values.T\n",
    "X_scaled = ddg_scaled.loc[top_clusters][common_agonists].values.T\n",
    "C = null_features.loc[common_agonists].values\n",
    "D_scaled = docking_normalized.loc[top_clusters][common_agonists].values.T\n",
    "\n",
    "\n",
    "features = [C, D_scaled]\n",
    "features_y = [C, D_scaled, y]\n",
    "feature_names = [\"Crystal Structures\", \"MSM States\"]\n",
    "\n",
    "#n_trials = 1000\n",
    "#test_accuracies, test_aucs, test_log_aucs, C_test_aucs, C_test_log_aucs, feature_importances = do_classification_experiment(features, y, feature_names, n_trials, 0.8, regularize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "def analyze_experiment(test_aucs, test_log_aucs, feature_importances, feature_names,\n",
    "                        X, y, top_clusters, common_agonists, experiment_name, save_dir):\n",
    "    \n",
    "    auc_df = pd.DataFrame(np.array(test_aucs), columns=feature_names)    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    g = (auc_df\n",
    "        .pipe((sns.violinplot, 'data'), orient='v', cut=0.))\n",
    "    #g = (auc_df\n",
    "    #    .pipe((sns.boxplot, 'data'), orient='v', showfliers=True))\n",
    "    g.set_xticklabels(auc_df.columns.values, rotation=90)\n",
    "    sns.despine()\n",
    "    plt.title(experiment_name)\n",
    "    plt.ylabel(\"Frequency AUCs over Random Splits\")\n",
    "    plt.xlabel(\"Featurization\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"%s/%s_aucs.pdf\" %(save_dir, experiment_name))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    docking_importances = [f[1] for f in feature_importances]\n",
    "    importances_df = make_importances_df(docking_importances, top_clusters)\n",
    "    importances_df.iloc[0:25].plot(kind='barh')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"MSM State\")\n",
    "    plt.title(experiment_name)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.savefig(\"%s/%s_feature_importances.pdf\" %(save_dir, experiment_name))\n",
    "    plt.clf()\n",
    "\n",
    "    cs = np.logspace(-3., 20.)\n",
    "    print(\"Computing regularization path ...\")\n",
    "    clf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n",
    "    coefs_ = []\n",
    "    for c in cs:\n",
    "        clf.set_params(C=c)\n",
    "        clf.fit(X, y)\n",
    "        coefs_.append(clf.coef_.ravel().copy())\n",
    "    \n",
    "    max_features = 5\n",
    "    coefs_ = pd.DataFrame(np.array(coefs_), columns=top_clusters, index=np.log10(cs))\n",
    "    coefs_[importances_df.iloc[:max_features].loc[samples_pnas_tica[\"tm6_tm3_dist\"] > 2.].index].plot(colormap='RdYlBu')\n",
    "    plt.xlabel(\"Lasso Parameter\")\n",
    "    plt.ylabel(\"Coefficient\")\n",
    "    plt.title(experiment_name)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.savefig(\"%s/%s_lasso.pdf\" %(save_dir, experiment_name))\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_clustermap(docking_normalized[common_agonists].loc[importances_df.index.values.tolist()[:max_features]].transpose(), save_file=\"%s/%s_ligands_vs_msm_states_ddg.pdf\" %(save_dir, experiment_name), method='average', z_score=None)\n",
    "    \n",
    "    return importances_df\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances_df = analyze_experiment(test_aucs, test_log_aucs, feature_importances, feature_names,\n",
    "                        D_scaled, y, top_clusters, common_agonists, \"Predicting Arrestin vs. G Protein Activity\", analysis_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ori = bret[\"B2AR-Gprotein, Mean\"].loc[common_agonists].values.reshape((-1,1))\n",
    "y = binarize(y_ori, threshold=0.05)\n",
    "\n",
    "X = delta_delta_g.loc[top_clusters][common_agonists].values.T\n",
    "X_scaled = ddg_scaled.loc[top_clusters][common_agonists].values.T\n",
    "C = null_features.loc[common_agonists].values\n",
    "D_scaled = docking_normalized.loc[top_clusters][common_agonists].values.T\n",
    "\n",
    "X_train = D_scaled\n",
    "y_train = y\n",
    "f = np.zeros(X_train.shape[1])\n",
    "\n",
    "rfr = RandomForestClassifier(n_estimators=1000, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "#top_indices = np.argsort(rfr.feature_importances_*-1.)[:min(20, X_train.shape[1])]\n",
    "#rfr = RandomForestClassifier(n_estimators=100, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "#X_train = X_train[:, top_indices]\n",
    "#rfr.fit(X_train, y_train)\n",
    "#f[top_indices] = rfr.feature_importances_\n",
    "#y_pred = rfr.predict(X_train)\n",
    "#y_score = rfr.predict_proba(X_train)\n",
    "top_indices=range(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#G Protein, Agonist Results\n",
    "test_drugs = secret_compounds + [\"nebivolol\", \"s-carvedilol\", \"xamoterol\", \"3p0g_lig\", \"isoetharine\", \"ethylnorepinephrine\", \"N-Cyclopentylbutanephrine\", \"ta-2005\", \"procaterol\"]\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "print(X_test)\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ARRESTIN, Agonist Results\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "X_test.shape\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#G Protein, Full Agonist Results\n",
    "test_drugs = secret_compounds + [\"nebivolol\", \"s-carvedilol\", \"xamoterol\", \"3p0g_lig\", \"isoetharine\", \"ethylnorepinephrine\", \"N-Cyclopentylbutanephrine\"]\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ARRESTIN, Agonist Results\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "X_test.shape\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_agonists = total_activity.loc[total_activity > 0.2].index.values\n",
    "plt.scatter(docking_normalized.loc[\"cluster21\"][common_agonists], bret[\"B2AR-Gprotein, Mean\"].subtract(bret[\"B2AR-Arrestin, Mean\"])[common_agonists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(common_ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ARRESTIN, Partial Agonist Results\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "X_test.shape\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ARRESTIN, Full Agonist Results\n",
    "X_test = docking_normalized.transpose().loc[test_drugs].values[:, top_indices]\n",
    "X_test.shape\n",
    "pd.DataFrame(rfr.predict_proba(X_test), index=test_drugs, columns=[\"P(Antagonist\", \"P(Agonist)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddg_scaled.transpose().loc[secret_compounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_clustermap(docking_normalized[secret_compounds].iloc[top_indices].transpose(), save_file=\"%s/mehrdad_clustermap.pdf\" %(save_dir), method='average', z_score=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(test_aucs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(ddg_scaled.loc[\"cluster11\"][common_agonists], y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arrestin_top = [16, 80, 43, 21, 84, 38, 44, 6, 13, 99]\n",
    "gprot_top = [44, 6, 83, 4, 76, 99, 62, 92, 39, 80]\n",
    "\n",
    "arrestin_only = sorted(list(set(arrestin_top).difference(set(gprot_top))))\n",
    "print(arrestin_only)\n",
    "gprot_only = sorted(list(set(gprot_top).difference(set(arrestin_top))))\n",
    "print(gprot_only)\n",
    "both = sorted(list(set(arrestin_top).intersection(set(gprot_top))))\n",
    "print(both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[importances_df.index.values.tolist()[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "reload(sklearn)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn import cross_validation\n",
    "\n",
    "test_accuracies = []\n",
    "test_aucs = []\n",
    "test_log_aucs = []\n",
    "C_test_aucs = []\n",
    "C_test_log_aucs = []\n",
    "n_trials = 10\n",
    "feature_importances = []\n",
    "total_activity = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].add(bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands])\n",
    "common_agonists = total_activity.loc[total_activity > 0.1].index.values\n",
    "\n",
    "#biased_ligands = [\"ethylnorepinephrine\", \"isoetharine\", \"N-Cyclopentylbutanephrine\"]\n",
    "#biased_ligands += [\"nebivolol\", \"s-carvedilol\"]\n",
    "#non_biased_ligands =  [\"r_isopreterenol\", \"r_epinephrine\", \"norepinephrine\", \"zinterol\", \"orciprenaline\", \"epinine\", \"terbutaline\", \"fenoterol\", \"procaterol\", \"formoterol\", \"salbutamol\", \"salmeterol\"]\n",
    "#non_biased_ligands += [\"s-carazolol\", \"Ici215001\", \"bisoprolol\", \"timolol\", \"s-atenolol\"]\n",
    "#non_biased_ligands = [n for n in df.columns.values.tolist() if n not in biased_ligands and \"Carvedilol\" not in n]\n",
    "#common_agonists = biased_ligands + non_biased_ligands\n",
    "#common_agonists = common_ligands\n",
    "#top_clusters = [\"cluster80\", \"cluster62\", \"cluster11\", \"cluster21\", \"cluster16\", \"cluster43\", \"cluster38\"]\n",
    "#differences = np.zeros((len(top_clusters), len(top_clusters)))\n",
    "#for i, cluster in enumerate(top_clusters):\n",
    "#    for j in range(i, len(top_clusters)):\n",
    "#        differences[i][j] = \n",
    "\n",
    "#top_clusters = importances_df.index.values\n",
    "top_clusters = delta_delta_g.index.values\n",
    "\n",
    "y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].subtract(bret[\"B2AR-Gprotein, Mean\"].loc[common_agonists]).values.reshape((-1,1))\n",
    "#y_ori = np.vstack([y_ori, np.ones(3).reshape((-1,1))])\n",
    "#common_agonists = common_agonists.tolist() + biased_ligands\n",
    "\n",
    "X = delta_delta_g.loc[top_clusters][common_agonists].values.T\n",
    "X_scaled = ddg_scaled.loc[top_clusters][common_agonists].values.T\n",
    "C = null_features.loc[common_agonists].values\n",
    "D_scaled = docking_normalized.loc[top_clusters][common_agonists].values.T\n",
    "\n",
    "#y = np.array([1. for n in biased_ligands] + [0. for n in non_biased_ligands]).reshape((-1,1))\n",
    "#print(y_ori)\n",
    "#y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].values.reshape((-1,1))\n",
    "#plt.hist(y_ori, bins=25)\n",
    "y = binarize(y_ori, threshold=-0.2)\n",
    "\n",
    "features = [C, X_scaled, D_scaled]\n",
    "features_y = [C, X_scaled, D_scaled, y]\n",
    "feature_names = [\"Crystal Structures\", \"MSM ddG\", \"Docking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xt = ddg_scaled[biased_ligands].values.T\n",
    "xt_preds = []\n",
    "\n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    print(j)\n",
    "    aucs = []\n",
    "    log_aucs = []\n",
    "    train_test_arrays = sklearn.cross_validation.train_test_split(*features_y, train_size=0.8, stratify=y) \n",
    "    y_train = train_test_arrays[2*len(features)]\n",
    "    y_test = train_test_arrays[2*len(features) + 1]\n",
    "    feature_importance = []\n",
    "    \n",
    "    for i in range(0, len(features)):\n",
    "        X_train = train_test_arrays[2*i]\n",
    "        X_test = train_test_arrays[2*i+1]\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        rfr = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=3, n_jobs=-1, oob_score=True)\n",
    "        rfr.fit(X_train, y_train)\n",
    "        #top_indices = np.argsort(rfr.feature_importances_*-1.)[:min(10, X.shape[1])]\n",
    "        feature_importance.append(rfr.feature_importances_)\n",
    "        #rfr = RandomForestClassifier(n_estimators=10, max_features=None, n_jobs=-1, oob_score=True)\n",
    "        #X_train = X_train[:, top_indices]\n",
    "        #X_test = X_test[:, top_indices]\n",
    "        #rfr.fit(X_train, y_train)\n",
    "        #f = np.zeros(X.shape[1])\n",
    "        #f[top_indices] = rfr.feature_importances_\n",
    "        #feature_importance.append(f)\n",
    "        \n",
    "        if i == 1:\n",
    "            xt_preds.append(rfr.predict(xt))\n",
    "        \n",
    "        y_pred = rfr.predict(X_test)\n",
    "        y_score = rfr.predict_proba(X_test)\n",
    "        auc, logauc = compute_auc(y_test, y_score)\n",
    "        aucs.append(auc)\n",
    "        log_aucs.append(logauc)  \n",
    "    feature_importances.append(feature_importance)\n",
    "    test_aucs.append(aucs)\n",
    "    test_log_aucs.append(log_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biased_ligands = [\"ethylnorepinephrine\", \"isoetharine\", \"N-Cyclopentylbutanephrine\"]\n",
    "\n",
    "non_biased_ligands =  [\"r_isopreterenol\", \"r_epinephrine\", \"norepinephrine\", \"zinterol\", \"orciprenaline\", \"epinine\", \"terbutaline\", \"fenoterol\", \"procaterol\", \"formoterol\", \"salbutamol\", \"salmeterol\"]\n",
    "\n",
    "ddg_scaled.loc[importances_df.index.values[:5]][biased_ligands + non_biased_ligands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddg_scaled.sort(\"procaterol\", inplace=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(ddg_scaled.loc[\"cluster36\"][common_agonists], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "reload(sklearn)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn import cross_validation\n",
    "\n",
    "test_accuracies = []\n",
    "test_aucs = []\n",
    "test_log_aucs = []\n",
    "C_test_aucs = []\n",
    "C_test_log_aucs = []\n",
    "n_trials = 1000\n",
    "feature_importances = []\n",
    "reg = []\n",
    "total_activity = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].add(bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands])\n",
    "common_agonists = total_activity.loc[total_activity > 0.3].index.values\n",
    "\n",
    "#biased_ligands = [\"ethylnorepinephrine\", \"isoetharine\", \"N-Cyclopentylbutanephrine\", \"3p0g_lig\"]\n",
    "#biased_ligands = [\"nebivolol\", \"s-carvedilol\"]\n",
    "#non_biased_ligands =  [\"r_isopreterenol\", \"r_epinephrine\", \"norepinephrine\", \"zinterol\", \"orciprenaline\", \"epinine\", \"terbutaline\", \"fenoterol\", \"procaterol\", \"formoterol\", \"salbutamol\", \"salmeterol\"]\n",
    "#non_biased_ligands = [\"s-carazolol\", \"Ici215001\", \"bisoprolol\", \"timolol\", \"s-atenolol\"]\n",
    "#non_biased_ligands = [n for n in df.columns.values.tolist() if n not in biased_ligands and \"Carvedilol\" not in n]\n",
    "#common_agonists = biased_ligands + non_biased_ligands\n",
    "\n",
    "X = delta_delta_g[common_agonists].values.T\n",
    "X_scaled = ddg_scaled[common_agonists].values.T\n",
    "C = null_features.loc[common_agonists].values\n",
    "\n",
    "#y = np.array([1. for n in biased_ligands] + [0. for n in non_biased_ligands]).reshape((-1,1))\n",
    "#y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].divide(bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].add(bret[\"B2AR-Gprotein, Mean\"].loc[common_agonists])).values.reshape((-1,1))\n",
    "y_ori = bret[\"B2AR-Arrestin, Mean\"].loc[common_agonists].values.reshape((-1,1))\n",
    "plt.hist(y_ori, bins=25)\n",
    "y = binarize(y_ori, threshold=0.2) \n",
    "\n",
    "features = [C, X, X_scaled, docking_normalized[common_agonists].values.T]\n",
    "features_y = [C, X, X_scaled, docking_normalized[common_agonists].values.T, y]\n",
    "feature_names = [\"Crystal Structures\", \"MSM States\", \"Normalized MSM States\", \"Normalized Docking\"]\n",
    "  \n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    print(j)\n",
    "    aucs = []\n",
    "    log_aucs = []\n",
    "    train_test_arrays = sklearn.cross_validation.train_test_split(*features_y, train_size=0.8, stratify=y) \n",
    "    y_train = train_test_arrays[2*len(features)]\n",
    "    y_test = train_test_arrays[2*len(features) + 1]\n",
    "    feature_importance = []\n",
    "    r = []\n",
    "    \n",
    "    for i in range(0, len(features)):\n",
    "        X_train = train_test_arrays[2*i]\n",
    "        X_test = train_test_arrays[2*i+1]\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train = sc.transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        cs = np.logspace(-3., 20.)\n",
    "        rfr = LogisticRegressionCV(Cs=cs, penalty='l2')\n",
    "        rfr.fit(X_train, y_train)\n",
    "        feature_importance.append(rfr.coef_)\n",
    "        y_pred = rfr.predict(X_test)\n",
    "        y_score = rfr.predict_proba(X_test)\n",
    "        auc, logauc = compute_auc(y_test, y_score)\n",
    "        aucs.append(auc)\n",
    "        log_aucs.append(logauc)  \n",
    "        r.append(rfr.C_)\n",
    "    reg.append(r)\n",
    "    feature_importances.append(feature_importance)\n",
    "    test_aucs.append(aucs)\n",
    "    test_log_aucs.append(log_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(docking_normalized.loc[\"cluster80\"][common_ligands], -1.0*bret.loc[common_ligands][\"B2AR-Gprotein, Mean\"].subtract(bret.loc[common_ligands][\"B2AR-Arrestin, Mean\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_df = pd.DataFrame(np.array(test_aucs), columns=feature_names)\n",
    "auc_df.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_df.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_docking_importances = [f[1] for f in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances_df = make_importances_df(normalized_docking_importances, top_clusters)\n",
    "importances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "X = ddg_scaled[common_ligands].values.T\n",
    "y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "y = binarize(y, threshold=0.5)\n",
    "print(np.shape(y))\n",
    "from sklearn.svm import l1_min_c\n",
    "from sklearn import linear_model\n",
    "\n",
    "#cs = l1_min_c(X, y, loss='log') * np.logspace(0, 3)\n",
    "cs = np.logspace(-3., 20.)\n",
    "print(\"Computing regularization path ...\")\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n",
    "coefs_ = []\n",
    "for c in cs:\n",
    "    clf.set_params(C=c)\n",
    "    clf.fit(X, y)\n",
    "    coefs_.append(clf.coef_.ravel().copy())\n",
    "\n",
    "coefs_ = pd.DataFrame(np.array(coefs_), columns=ddg_scaled.index.values, index=np.log10(cs))\n",
    "#coefs_[list(set(inactive_clusters.tolist()).intersection(set(importances_df.iloc[10:20].index.values.tolist())))].plot()\n",
    "coefs_[importances_df.index.values[:5]].plot()\n",
    "#plt.plot(np.log10(cs), coefs_)\n",
    "#ymin, ymax = plt.ylim()\n",
    "###plt.xlabel('log(C)')\n",
    "#plt.ylabel('Coefficients')\n",
    "##plt.title('Logistic Regression Path')\n",
    "#plt.axis('tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[importances_df.index.values[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(deltas_tica.loc[importances_df.index.values[:10]][\"tIC.6\"], coefs_[importances_df.index.values[:10]].values[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_clustermap(ddg_scaled[common_agonists.tolist()].loc[importances_df.index.values.tolist()[:5]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='average')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[samples_pnas_tica[\"tm6_tm3_dist\"] < 18.0].loc[importances_df.iloc[0:5].index].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddg_scaled[\"nebivolol\"].subtract(ddg_scaled[\"s-carazolol\"]).sort(inplace=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddg_scaled[\"s-carvedilol\"].subtract(ddg_scaled[\"s-carazolol\"]).sort(inplace=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[[\"cluster74\", \"cluster69\", \"cluster13\", \"cluster12\", \"cluster66\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "#plot_importances_barh(importances_df.values, importances_df.index.values, \"MSM State Importance in Arrestin Prediction\", \"Feature Importance\", \"MSM State\", \"%s/arrestin_0pt5_classification_rfr.pdf\" %(tica_dir), n_features=50)\n",
    "importances_df.iloc[0:25].plot(kind='barh')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"MSM State\")\n",
    "plt.title(\"Importance of MSM States in Predicting Arrestin Activity\")\n",
    "plt.savefig(\"%s/msm_%dstates_arrestin_0pt2_agonists_only_classification_rfr.pdf\" %(tica_dir, n_clusters))\n",
    "#plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = docking_normalized[common_agonists].values.T\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].subtract(bret[\"B2AR-Gprotein, Mean\"]).loc[common_agonists].values.reshape((-1,1))\n",
    "y = binarize(y, threshold=-0.2)\n",
    "print(y)\n",
    "from sklearn import linear_model\n",
    "\n",
    "cs = np.logspace(-3., 200.)\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l2', tol=1e-6)\n",
    "coefs_ = []\n",
    "for c in cs:\n",
    "    clf.set_params(C=c)\n",
    "    clf.fit(X, y)\n",
    "    coefs_.append(clf.coef_.ravel().copy())\n",
    "\n",
    "coefs_ = pd.DataFrame(np.array(coefs_), columns=ddg_scaled.index.values, index=np.log10(cs))\n",
    "coefs_[importances_df.iloc[0:10].loc[samples_pnas_tica[\"tm6_tm3_dist\"] < 9.].index].plot()\n",
    "plt.xlabel(\"Log Regularization Parameter\")\n",
    "plt.ylabel(\"Coefficient for Arrestin Activity\")\n",
    "plt.title(\"Logistic Regression Coefficient in Predicting Arrestin Activity\")\n",
    "plt.savefig(\"%s/msm_%dstates_arrestin_0pt2_agonists_only_classification_logistic.pdf\" %(tica_dir, n_clusters))\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(np.nan_to_num(test_aucs)))\n",
    "print(np.median(np.nan_to_num(C_test_aucs)))\n",
    "print(np.median(np.nan_to_num(test_log_aucs)))\n",
    "print(np.median(np.nan_to_num(C_test_log_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "states = importances_df.index.values.tolist()\n",
    "model = lr.fit(X, y_ori)\n",
    "pd.DataFrame(model.coef_.T, index=delta_delta_g.index, columns=[\"importance\"]).loc[states]#.sort(\"importance\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "reload(seaborn)\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "g = (auc_df\n",
    "    .pipe((sns.boxplot, 'data'), orient='v', showfliers=True))\n",
    "g.set_xticklabels(auc_df.columns.values, rotation=90)\n",
    "sns.despine()\n",
    "plt.title(\"AUC for Arrestin Prediction\")\n",
    "plt.ylabel(\"Frequency AUCs over Random Splits\")\n",
    "plt.xlabel(\"Featurization\")\n",
    "plt.show()\n",
    "plt.savefig(\"%s/auc_arrestin_prediction_all_ligands_0pt2_cutoff.pdf\" %tica_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = compute_pearson_matrix(delta_delta_g[common_agonists].values.T, y)\n",
    "corr_df = pd.DataFrame(model.coef_.T, index=delta_delta_g.index.values, columns=[\"Correlation\"]).sort(\"Correlation\",inplace=False)\n",
    "#corr_df.loc[[\"cluster80\", \"cluster16\", \"cluster43\", \"cluster44\"]].plot(kind='barh')\n",
    "corr_df.loc[importances_df.index.values[:20]].sort(\"Correlation\", inplace=False).plot(kind='barh')#, figsize=(5,20))\n",
    "plt.xlabel(\"Pearsson Correlation with Arrestin Activity\")\n",
    "plt.ylabel(\"MSM State\")\n",
    "plt.title(\"Correlation of MSM States with Arrestin Activity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[corr_df.loc[importances_df.index.values[:20]].sort(\"Correlation\", inplace=False).index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = copy.deepcopy(aggregate_docking_msm)\n",
    "df[df.columns.values] = scale(df.values)\n",
    "plt.scatter(df[common_ligands].loc[\"cluster13\"].values, bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "reload(sklearn)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn import cross_validation\n",
    "\n",
    "test_accuracies = []\n",
    "test_aucs = []\n",
    "test_log_aucs = []\n",
    "C_test_aucs = []\n",
    "C_test_log_aucs = []\n",
    "n_trials = 100\n",
    "feature_importances = []\n",
    "\n",
    "for j in range(0,n_trials):\n",
    "    print(j)\n",
    "\n",
    "    X = delta_delta_g[common_ligands].values.T\n",
    "    C = null_features.loc[common_ligands].values\n",
    "    y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "    y = binarize(y, threshold=0.5)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = sklearn.cross_validation.train_test_split(X, y, C, train_size=0.8, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    C_train = sc.transform(C_train)\n",
    "    C_test = sc.transform(C_test)\n",
    " \n",
    "    rfr = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    feature_importances.append(rfr.feature_importances_)\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    test_accuracies.append(np.sqrt(np.mean(np.square(y_test-y_pred.reshape((-1,1))))))\n",
    "    y_score = rfr.predict_proba(X_test)\n",
    "    auc, logauc = compute_auc(y_test, y_score)\n",
    "    test_aucs.append(auc)\n",
    "    test_log_aucs.append(logauc)\n",
    "    \n",
    "    rfr = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=2, n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train, y_train)\n",
    "    C_y_pred = rfr.predict(C_test)\n",
    "    y_score = rfr.predict_proba(C_test)\n",
    "    auc, logauc = compute_auc(y_test, y_score)\n",
    "    C_test_aucs.append(auc)\n",
    "    C_test_log_aucs.append(logauc)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "reload(seaborn)\n",
    "import seaborn as sns\n",
    "auc_df = pd.DataFrame(np.vstack([test_aucs, C_test_aucs]).T, columns=[\"MSM States\", \"Crystal Structures\"])\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.set_style(\"darkgrid\")\n",
    "g = (auc_df\n",
    "    .pipe((sns.boxplot, 'data'), orient='v', showfliers=True))\n",
    "#g.set_xticklabels(experiments.columns.values, rotation=90)\n",
    "sns.despine()\n",
    "plt.title(\"AUC for G Protein Prediction\")\n",
    "plt.ylabel(\"Frequency AUCs over Random Splits\")\n",
    "plt.xlabel(\"Featurization\")\n",
    "plt.show()\n",
    "plt.savefig(\"%s/msm_n-states%d_auc_gprot_prediction_cutoff0pt5.pdf\" %(tica_dir, n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df = make_importances_df(feature_importances, delta_delta_g.index.values.tolist())\n",
    "importances_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "model = Lasso(alpha=0.0001)                                \n",
    "model.fit(ddg_scaled[common_agonists].values.T, bret.loc[common_agonists][\"B2AR-Arrestin, Mean\"].subtract(bret.loc[common_agonists][\"B2AR-Gprotein, Mean\"].values))\n",
    "pd.DataFrame(model.coef_, index=ddg_scaled.index, columns=[\"importance\"]).sort(\"importance\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(np.nan_to_num(test_aucs)))\n",
    "print(np.median(np.nan_to_num(C_test_aucs)))\n",
    "print(np.median(np.nan_to_num(test_log_aucs)))\n",
    "print(np.median(np.nan_to_num(C_test_log_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "#plot_importances_barh(importances_df.values, importances_df.index.values, \"MSM State Importance in Arrestin Prediction\", \"Feature Importance\", \"MSM State\", \"%s/arrestin_0pt5_classification_rfr.pdf\" %(tica_dir), n_features=50)\n",
    "importances_df.iloc[0:25].plot(kind='barh')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"MSM State\")\n",
    "plt.title(\"Importance of MSM States in Predicting G Protein Activity\")\n",
    "#plt.savefig(\"%s/msm_%dstates_gprot_0pt5_classification_rfr.pdf\" %(tica_dir, n_clusters))\n",
    "#plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = compute_pearson_matrix(ddg_scaled[common_ligands].values.T, y)\n",
    "corr_df = pd.DataFrame(model.coef_, index=ddg_scaled.index.values, columns=[\"Correlation\"])\n",
    "corr_df.loc[importances_df.index.values[:10]].sort(\"Correlation\", inplace=False).plot(kind='barh')\n",
    "plt.xlabel(\"Pearsson Correlation with G Protein Activity\")\n",
    "plt.ylabel(\"MSM State\")\n",
    "plt.title(\"Correlation of MSM States with G Protein Activity\")\n",
    "#plt.savefig(\"%s/msm_%dstates_gprot_0pt5_classification_correlations.pdf\" %(tica_dir, n_clusters))\n",
    "#plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_pnas_tica.loc[importances_df.index.values[:10]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from random import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features='sqrt', n_jobs=-1)\n",
    "common_ligands = [n for n in bret.index.values if n in delta_delta_g.columns.values]\n",
    "shuffle(common_ligands)\n",
    "X = delta_delta_g[common_ligands].values\n",
    "X = np.vstack([X, scale(X)]).T\n",
    "#X = scale(X).T\n",
    "print(np.shape(X))\n",
    "y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "threshold = 0.2\n",
    "y = binarize(y, threshold=threshold)\n",
    "print(np.shape(y))\n",
    "nb_train = 0.8 * np.shape(X)[0]\n",
    "X_train = X[:nb_train,:]\n",
    "y_train = y[:nb_train,:]\n",
    "X_test = X[nb_train:,:]\n",
    "y_test = y[nb_train:,:]\n",
    "rfc.fit(X_train,y_train)\n",
    "y_score = rfc.predict_proba(X_test)\n",
    "print(y_score)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:,1])\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#X_test = delta_delta_g.loc[delta_delta_g[\"label\"] == 0][[t for t in delta_delta_g.columns.values if t != \"label\"]]\n",
    "#pd.DataFrame(dt.predict(pd.concat([X, X_test])), index=pd.concat([X, X_test]).index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logauc(fpr, tpr, lam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_exp = 100\n",
    "aucs = [] \n",
    "for i in range(0, n_exp):\n",
    "    rfc = RandomForestClassifier(n_estimators=100, max_features='sqrt', n_jobs=-1)\n",
    "    common_ligands = [n for n in bret.index.values if n in delta_delta_g.columns.values]\n",
    "    shuffle(common_ligands)\n",
    "    X = delta_delta_g[common_ligands].values\n",
    "    X = np.vstack([X, scale(X)]).T\n",
    "    #X = scale(X).T\n",
    "    y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "    threshold = 0.2\n",
    "    y = binarize(y, threshold=threshold)\n",
    "    nb_train = 0.8 * np.shape(X)[0]\n",
    "    \n",
    "    X_train = X[:nb_train,:]\n",
    "    y_train = y[:nb_train,:]\n",
    "    X_test = X[nb_train:,:]\n",
    "    y_test = y[nb_train:,:]\n",
    "    rfc.fit(X_train,y_train)\n",
    "    y_score = rfc.predict_proba(X_test)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score[:,1])\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.nan_to_num(aucs))\n",
    "plt.title(\"AUC for G Protein Agonism Classification, 0.2\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from random import shuffle\n",
    "rfr = RandomForestRegressor(n_estimators=1000, max_features='sqrt', n_jobs=-1)\n",
    "shuffle(common_ligands)\n",
    "X = delta_delta_g[common_ligands].values.T\n",
    "#X = np.vstack([X, scale(X)]).T\n",
    "#X = scale(X).T\n",
    "print(np.shape(X))\n",
    "y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "print(np.shape(y))\n",
    "nb_train = 0.8 * np.shape(X)[0]\n",
    "X_train = X[:nb_train,:]\n",
    "y_train = y[:nb_train,:]\n",
    "X_test = X[nb_train:,:]\n",
    "y_test = y[nb_train:,:]\n",
    "rfr.fit(X_train,y_train)\n",
    "#X_test = delta_delta_g.loc[delta_delta_g[\"label\"] == 0][[t for t in delta_delta_g.columns.values if t != \"label\"]]\n",
    "#pd.DataFrame(dt.predict(pd.concat([X, X_test])), index=pd.concat([X, X_test]).index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "plt.scatter(rfr.predict(X_train),y_train)\n",
    "plt.xlabel(\"Predicted G Protein Activity\")\n",
    "plt.ylabel(\"Experimental G Protein Activity\")\n",
    "plt.title(\"Random Forest Regression for G Protein Activity: Train\")\n",
    "\n",
    "pp = PdfPages(\"%s/gprot_rfr_train.pdf\" % docking_dir)\n",
    "pp.savefig(bbox_inches='tight')\n",
    "pp.close()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(rfr.predict(X_test),y_test)\n",
    "plt.xlabel(\"Predicted G Protein Activity\")\n",
    "plt.ylabel(\"Experimental G Protein Activity\")\n",
    "plt.title(\"Random Forest Regression for G Protein Activity: Test\")\n",
    "\n",
    "pp = PdfPages(\"%s/gprot_rfr_test.pdf\" % docking_dir)\n",
    "pp.savefig(bbox_inches='tight')\n",
    "pp.close()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "test_accuracies = []\n",
    "test_r2s = []\n",
    "C_test_accuracies = []\n",
    "C_test_r2s = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    n_exp = 1\n",
    "    accuracies = []\n",
    "    r2s = []\n",
    "    importances = []\n",
    "\n",
    "    gbr_accuracies = []\n",
    "    gbr_r2s = []\n",
    "    gbr_importances = []\n",
    "\n",
    "    oob_scores = []\n",
    "\n",
    "    C_accuracies = []\n",
    "    C_r2s = []\n",
    "    C_importances = []\n",
    "    C_oob_scores = []\n",
    "\n",
    "    C_gbr_accuracies = []\n",
    "    C_gbr_r2s = []\n",
    "    C_gbr_importances = []\n",
    "\n",
    "    X = delta_delta_g[common_ligands].values.T\n",
    "    C = null_features.loc[common_ligands].values\n",
    "    y = bret[\"B2AR-Gprotein, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "\n",
    "    X, X_pristine, y, y_pristine, C, C_pristine = train_test_split(X, y, C, train_size=0.7)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(0, n_exp):\n",
    "        X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train = np.hstack([X_train, sc.transform(X_train)])\n",
    "        X_test = np.hstack([X_test, sc.transform(X_test)])\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(C_train)\n",
    "        C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "        C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "\n",
    "        rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "        rfr.fit(X_train,y_train)\n",
    "        accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "        r2s.append(r2_score(y_test, rfr.predict(X_test)))\n",
    "        importances.append(rfr.feature_importances_)\n",
    "        oob_scores.append(rfr.oob_score_)\n",
    "    mean_importances = np.mean(np.vstack(importances), axis=0)\n",
    "    top_features = np.argsort(-1.0*mean_importances)[0:5]\n",
    "    print(top_features)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X_train = np.hstack([X, sc.transform(X)])\n",
    "    X_test = np.hstack([X_pristine, sc.transform(X_pristine)])\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C)\n",
    "    C_train = np.hstack([C, sc.transform(C)])\n",
    "    C_test = np.hstack([C_pristine, sc.transform(C_pristine)])\n",
    "\n",
    "    y_train = y\n",
    "    y_test = y_pristine\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    test_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "    test_r2s.append(r2_score(y_test, rfr.predict(X_test)))\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train, y_train)\n",
    "    C_test_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(C_test).reshape((-1,1))))))\n",
    "    C_test_r2s.append(r2_score(y_test, rfr.predict(C_test)))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(test_accuracies))\n",
    "print(np.mean(test_r2s))\n",
    "print(np.mean(C_test_accuracies))\n",
    "print(np.mean(C_test_r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(test_accuracies))\n",
    "print(np.mean(test_r2s))\n",
    "print(np.mean(C_test_accuracies))\n",
    "print(np.mean(C_test_r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(accuracies))\n",
    "print(np.median(r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_importances = np.mean(np.vstack(importances), axis=0)\n",
    "top_features = np.argsort(-1.0*mean_importances)[0:10]\n",
    "print(top_features)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_train = np.hstack([X, sc.transform(X)])\n",
    "X_test = np.hstack([X_pristine, sc.transform(X_pristine)])\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(C)\n",
    "C_train = np.hstack([C, sc.transform(C)])\n",
    "C_test = np.hstack([C_pristine, sc.transform(C_pristine)])\n",
    "\n",
    "y_train = y\n",
    "y_test = y_pristine\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"RMSE:\")\n",
    "print(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "print(\"r2_score:\")\n",
    "print(r2_score(y_test, rfr.predict(X_test)))\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "rfr.fit(C_train, y_train)\n",
    "print(\"RMSE:\")\n",
    "print(np.sqrt(np.mean(np.square(y_test-rfr.predict(C_test).reshape((-1,1))))))\n",
    "print(\"r2_score:\")\n",
    "print(r2_score(y_test, rfr.predict(C_test)))\n",
    "#importances.append(rfr.feature_importances_)\n",
    "#oob_scores.append(rfr.oob_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " np.argsort(-1.0*mean_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(C_r2s, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(r2s, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.mean(np.vstack(importances), axis=0), columns=[\"importance\"]).sort(\"importance\",inplace=False).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(C_oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(C_r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(C_r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(C_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(C_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(C_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(C_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(rfr.predict(C_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_importances = np.median(np.array(importances), axis=0)\n",
    "gprot_importances_df = pd.DataFrame(med_importances, index=aggregate_docking_msm.index.values.tolist() + [\"%s_scaled\" %n for n in aggregate_docking_msm.index.values.tolist()], columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import SparsePCA, PCA\n",
    "n_exp = 100\n",
    "accuracies = []\n",
    "r2s = []\n",
    "importances = []\n",
    "\n",
    "gbr_accuracies = []\n",
    "gbr_r2s = []\n",
    "gbr_importances = []\n",
    "\n",
    "oob_scores = []\n",
    "\n",
    "C_accuracies = []\n",
    "C_r2s = []\n",
    "C_importances = []\n",
    "C_oob_scores = []\n",
    "\n",
    "C_gbr_accuracies = []\n",
    "C_gbr_r2s = []\n",
    "C_gbr_importances = []\n",
    "\n",
    "X = delta_delta_g[common_ligands].iloc[[62, 80, 16, 61]].values.T\n",
    "C = null_features.loc[common_ligands].values\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "\n",
    "for i in range(0, n_exp):\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.9)\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = np.hstack([X_train, sc.transform(X_train)])\n",
    "    X_test = np.hstack([X_test, sc.transform(X_test)])\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "    C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train,y_train)\n",
    "    accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "    r2s.append(r2_score(y_test, rfr.predict(X_test)))\n",
    "    importances.append(rfr.feature_importances_)\n",
    "    oob_scores.append(rfr.oob_score_)\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train,y_train)\n",
    "    C_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(C_test).reshape((-1,1))))))\n",
    "    C_r2s.append(r2_score(y_test, rfr.predict(C_test)))\n",
    "    C_importances.append(rfr.feature_importances_)\n",
    "    C_oob_scores.append(rfr.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(accuracies))\n",
    "print(np.median(C_accuracies))\n",
    "print(np.median(gbr_accuracies))\n",
    "print(np.median(C_gbr_accuracies))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.median(r2s))\n",
    "print(np.median(C_r2s))\n",
    "print(np.median(gbr_r2s))\n",
    "print(np.median(C_gbr_r2s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import SparsePCA, PCA\n",
    "n_exp = 10\n",
    "accuracies = []\n",
    "r2s = []\n",
    "importances = []\n",
    "\n",
    "gbr_accuracies = []\n",
    "gbr_r2s = []\n",
    "gbr_importances = []\n",
    "\n",
    "oob_scores = []\n",
    "\n",
    "C_accuracies = []\n",
    "C_r2s = []\n",
    "C_importances = []\n",
    "C_oob_scores = []\n",
    "\n",
    "C_gbr_accuracies = []\n",
    "C_gbr_r2s = []\n",
    "C_gbr_importances = []\n",
    "\n",
    "#X = delta_delta_g[common_ligands].iloc[[16, 80, 61, 62]].values.T\n",
    "#spca = SparsePCA(n_components=20, alpha=2.)\n",
    "pca = PCA(n_components=10)\n",
    "X = pca.fit_transform(X)\n",
    "#print(spca.components_)\n",
    "C = null_features.loc[common_ligands].values\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "\n",
    "for i in range(0, n_exp):\n",
    "    X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C, train_size=0.8)\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = np.hstack([X_train, sc.transform(X_train)])\n",
    "    X_test = np.hstack([X_test, sc.transform(X_test)])\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(C_train)\n",
    "    C_train = np.hstack([C_train, sc.transform(C_train)])\n",
    "    C_test = np.hstack([C_test, sc.transform(C_test)])\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_depth=2, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(X_train,y_train)\n",
    "    accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "    r2s.append(r2_score(y_test, rfr.predict(X_test)))\n",
    "    importances.append(rfr.feature_importances_)\n",
    "    oob_scores.append(rfr.oob_score_)\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_depth=2, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "    rfr.fit(C_train,y_train)\n",
    "    C_accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(C_test).reshape((-1,1))))))\n",
    "    C_r2s.append(r2_score(y_test, rfr.predict(C_test)))\n",
    "    C_importances.append(rfr.feature_importances_)\n",
    "    C_oob_scores.append(rfr.oob_score_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.median(accuracies))\n",
    "print(np.median(C_accuracies))\n",
    "print(np.median(r2s))\n",
    "print(np.median(C_r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "names = [n.split(\"_scaled\")[0] for n in gprot_importances_df.index.values.tolist()]\n",
    "new_names = []\n",
    "for n in names:\n",
    "    if n not in new_names: new_names.append(n)\n",
    "plot_clustermap(pd.concat([samples_top_features_avg_df, samples_pnas_avg_df, ddg_scaled[[\"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"r_isopreterenol\", \"nebivolol\", \"s-carvedilol\", \"s-carazolol\", \"s-atenolol\", \"pindolol\", \"propranolol\", 'Ici118551']]],axis=1).loc[new_names[:10]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d_arrestin_agonist_features.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='single', col_cluster=True, row_cluster=False, ytick_labelsize=8, xtick_labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gprot_importances_df.iloc[0:50].plot(kind='barh', figsize=(4,15), title=\"RFR Feature Importance: GProtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(accuracies, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agonist_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame(rfr.feature_importances_, index=aggregate_docking_msm.index.values.tolist(),  columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)\n",
    "                              #+ [\"%s_scaled\" %f for f in aggregate_docking_msm.index.values] ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(aggregate_docking_msm.index.values + [\"%s_scaled\" %f for f in aggregate_docking_msm.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deltas_tica.loc[importances_df.index][[\"r_isopreterenol\", \"bisoprolol\", \"tm6_tm3_dist\", \"rmsd_npxxy_active\", \"tIC.1\"]].iloc[0:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df.plot(kind='bar', figsize=(15,4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(0,100), deltas_tica.loc[importances_df.index][\"tIC.2\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import detect_intermediates\n",
    "reload(detect_intermediates)\n",
    "from detect_intermediates import *\n",
    "plot_df_rolling(deltas_tica.loc[importances_df.index][[\"tIC.1\", \"tIC.2\", \"tIC.3\", \"tm6_tm3_dist\", \"rmsd_npxxy_active\"]], \"%s/tICA_vs_rfr_importance_agonists.pdf\" %docking_dir, return_fig=True, subplots=True, smoothing=5, include_original=False)\n",
    "#pd.rolling_mean(deltas_tica.loc[importances_df.index][[\"tIC.1\", \"tIC.2\", \"tIC.3\", \"tm6_tm3_dist\", \"rmsd_npxxy_active\"]], 25).plot(colormap='gist_rainbow', subplots=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "#plot_df_rolling(samples_top_features_avg_df.loc[importances_df.index], \"%s/features_vs_rfr_importance_arrestin_agonists.pdf\" %docking_dir, return_fig=True, subplots=True, smoothing=5, include_original=False)\n",
    "plot_clustermap(samples_top_features_avg_df.loc[importances_df.index].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d_gprot_agonist_features.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='single', col_cluster=False)\n",
    "\n",
    "#plot_clustermap(deltas_tica[[\"tm6_tm3_dist\", \"rmsd_npxxy_active\", \"3p0g_lig\"]].loc[importances_df.index].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d_gprot_agonist_features.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='single', col_cluster=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = delta_delta_g[common_ligands].values.T\n",
    "print(np.shape(X))\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "print(np.shape(y))\n",
    "nb_train = int(0.8 * np.shape(X)[0])\n",
    "X_train = X[:nb_train,:]\n",
    "y_train = y[:nb_train,:]\n",
    "X_test = X[nb_train:,:]\n",
    "y_test = y[nb_train:,:]\n",
    "rfr.fit(X_train,y_train)\n",
    "print(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000, max_features='sqrt', n_jobs=-1)\n",
    "common_ligands = [n for n in bret.index.values if n in delta_delta_g.columns.values]\n",
    "shuffle(common_ligands)\n",
    "X = delta_delta_g[common_ligands].values\n",
    "X = np.vstack([X, scale(X)]).T\n",
    "#X = scale(X).T\n",
    "print(np.shape(X))\n",
    "y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "threshold = 0.5\n",
    "y = binarize(y, threshold=threshold)\n",
    "print(np.shape(y))\n",
    "nb_train = 0.8 * np.shape(X)[0]\n",
    "X_train = X[:nb_train,:]\n",
    "y_train = y[:nb_train,:]\n",
    "X_test = X[nb_train:,:]\n",
    "y_test = y[nb_train:,:]\n",
    "rfc.fit(X_train,y_train)\n",
    "y_score = rfc.predict_proba(X_test)\n",
    "print(y_score)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:,1])\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#X_test = delta_delta_g.loc[delta_delta_g[\"label\"] == 0][[t for t in delta_delta_g.columns.values if t != \"label\"]]\n",
    "#pd.DataFrame(dt.predict(pd.concat([X, X_test])), index=pd.concat([X, X_test]).index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_exp = 100\n",
    "aucs = []\n",
    "for i in range(0, n_exp):\n",
    "    rfc = RandomForestClassifier(n_estimators=100, max_features='sqrt', n_jobs=-1)\n",
    "    common_ligands = [n for n in bret.index.values if n in delta_delta_g.columns.values]\n",
    "    shuffle(common_ligands)\n",
    "    X = delta_delta_g[common_ligands].values\n",
    "    X = np.vstack([X, scale(X)]).T\n",
    "    #X = scale(X).T\n",
    "    y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "    threshold = 0.8\n",
    "    y = binarize(y, threshold=threshold)\n",
    "    nb_train = 0.8 * np.shape(X)[0]\n",
    "    X_train = X[:nb_train,:]\n",
    "    y_train = y[:nb_train,:]\n",
    "    X_test = X[nb_train:,:]\n",
    "    y_test = y[nb_train:,:]\n",
    "    rfc.fit(X_train,y_train)\n",
    "    y_score = rfc.predict_proba(X_test)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score[:,1])\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.nan_to_num(aucs))\n",
    "plt.title(\"AUC for Arrestin Agonism Classification, 0.8\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame(rfr.feature_importances_, index=aggregate_docking_msm.index, columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(rfr.predict(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(rfr.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(rfr.feature_importances_, index=aggregate_docking_msm.index, columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_exp = 100\n",
    "accuracies = []\n",
    "r2s = []\n",
    "importances = []\n",
    "for i in range(0, n_exp):\n",
    "    rfr = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=-1)\n",
    "    shuffle(common_ligands)\n",
    "    X = delta_delta_g[common_ligands].values\n",
    "    X = np.vstack([X, scale(X)]).T\n",
    "    y = bret[\"B2AR-Arrestin, Mean\"].loc[common_ligands].values.reshape((-1,1))\n",
    "    nb_train = int(0.8 * np.shape(X)[0])\n",
    "    X_train = X[:nb_train,:]\n",
    "    y_train = y[:nb_train,:]\n",
    "    X_test = X[nb_train:,:]\n",
    "    y_test = y[nb_train:,:]\n",
    "    rfr.fit(X_train,y_train)\n",
    "    accuracies.append(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))\n",
    "    r2s.append(rfr.score(X_test, y_test))\n",
    "    importances.append(rfr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(accuracies, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(r2s, showfliers=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_importances = np.median(np.array(importances), axis=0)\n",
    "importances_df = pd.DataFrame(med_importances, index=aggregate_docking_msm.index.values.tolist() + [\"%s_scaled\" %n for n in aggregate_docking_msm.index.values.tolist()], columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df.iloc[0:50].plot(kind='barh', figsize=(4,15), title=\"RFR Feature Importance: Arrestin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plots\n",
    "reload(plots)\n",
    "from plots import *\n",
    "names = [n.split(\"_scaled\")[0] for n in importances_df.index.values.tolist()]\n",
    "new_names = []\n",
    "for n in names:\n",
    "    if n not in new_names: new_names.append(n)\n",
    "plot_clustermap(pd.concat([samples_top_features_avg_df, samples_pnas_avg_df, ddg_scaled[[\"norepinephrine\", \"r_epinephrine\", \"ethylnorepinephrine\", \"r_isopreterenol\", \"nebivolol\", \"s-carvedilol\", \"s-carazolol\", \"s-atenolol\", \"pindolol\", \"propranolol\", 'Ici118551']]],axis=1).loc[new_names[:10]].transpose(), save_file=\"%s/msm_n-clusters%d_lag-time%d_tICs%d_arrestin_agonist_features.pdf\" %(tica_dir, n_clusters, msm_lag_time, n_components), method='single', col_cluster=True, row_cluster=False, ytick_labelsize=8, xtick_labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddg_scaled[[\"r_isopreterenol\", \"salbutamol\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_80 = []\n",
    "top_features_80 = samples_normalized_features_avg_df.loc[\"cluster80\"].loc[samples_normalized_features_avg_df.loc[\"cluster80\"].abs() > 1.].index.values\n",
    "print(top_features_80)\n",
    "print(len(top_features_80))\n",
    "#[top_features_80.append(pair) for pair in samples_normalized_features_avg_df.iloc[80].sort(inplace=False).index.values[:50]]\n",
    "#[top_features_80.append(pair) for pair in samples_normalized_features_avg_df.iloc[80].sort(inplace=False, ascending=False).index.values[:50]]\n",
    "features = []\n",
    "for f in top_features_80:\n",
    "    fs = f.split(\",\")\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_80 = list(set(features))\n",
    "print(top_features_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_13 = []\n",
    "top_features_13 = samples_normalized_features_avg_df.loc[\"cluster13\"].loc[samples_normalized_features_avg_df.loc[\"cluster13\"].abs() > 1.].index.values\n",
    "print(top_features_13)\n",
    "print(len(top_features_13))\n",
    "#[top_features_13.append(pair) for pair in samples_normalized_features_avg_df.iloc[13].sort(inplace=False).index.values[:50]]\n",
    "#[top_features_13.append(pair) for pair in samples_normalized_features_avg_df.iloc[13].sort(inplace=False, ascending=False).index.values[:50]]\n",
    "features = []\n",
    "for f in top_features_13:\n",
    "    fs = f.split(\",\")\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_13 = list(set(features))\n",
    "print(sorted(top_features_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_44 = []\n",
    "top_features_44 = samples_normalized_features_avg_df.loc[\"cluster44\"].loc[samples_normalized_features_avg_df.loc[\"cluster44\"].abs() > 1.].index.values\n",
    "print(top_features_44)\n",
    "print(len(top_features_44))\n",
    "#[top_features_44.append(pair) for pair in samples_normalized_features_avg_df.iloc[44].sort(inplace=False).index.values[:50]]\n",
    "#[top_features_44.append(pair) for pair in samples_normalized_features_avg_df.iloc[44].sort(inplace=False, ascending=False).index.values[:50]]\n",
    "features = []\n",
    "for f in top_features_44:\n",
    "    fs = f.split(\",\")\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_44 = list(set(features))\n",
    "print(top_features_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(list(set([f for f in (top_features_13 + top_features_44) if f not in top_features_44 and f in top_features_13])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_measurable_features(samples_normalized_features_avg_df, cluster_name):\n",
    "    import re\n",
    "    top_features_cluster = []\n",
    "    #top_features_cluster = samples_normalized_features_avg_df.loc[\"cluster_name\"].loc[samples_normalized_features_avg_df.loc[\"cluster_name\"].abs() > .75].index.values\n",
    "    #print(top_features_cluster)\n",
    "    #print(len(top_features_cluster))\n",
    "    [top_features_cluster.append(pair) for pair in samples_normalized_features_avg_df.loc[cluster_name].abs().sort(inplace=False, ascending=False).index.values[:100]]\n",
    "    all_features = []\n",
    "    features = []\n",
    "    for f in top_features_cluster:\n",
    "        fs = f.split(\",\")\n",
    "        for i in range(0, len(fs)):\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            all_features.append(res)\n",
    "            if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "                features.append(res)\n",
    "            \n",
    "    top_features_cluster = sorted(list(set(features)))\n",
    "    #print(sorted(list(set([int(re.findall(r'\\d+', r)[0]) for r in all_features]))))\n",
    "    #print(top_features_cluster)\n",
    "    return top_features_cluster, all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_different_measurable_features(samples_normalized_features_avg_df, cluster_i, cluster_j):\n",
    "    import re\n",
    "    top_features_cluster = []\n",
    "    #top_features_cluster = samples_normalized_features_avg_df.loc[\"cluster_name\"].loc[samples_normalized_features_avg_df.loc[\"cluster_name\"].abs() > .75].index.values\n",
    "    #print(top_features_cluster)\n",
    "    #print(len(top_features_cluster))\n",
    "    df = samples_normalized_features_avg_df.loc[cluster_i].subtract(samples_normalized_features_avg_df.loc[cluster_j]).abs()\n",
    "    print(df.sort(inplace=False, ascending=False))\n",
    "    [top_features_cluster.append(pair) for pair in df.sort(inplace=False, ascending=False).index.values[:25]]\n",
    "    all_features = []\n",
    "    features = []\n",
    "    for f in top_features_cluster:\n",
    "        fs = f.split(\",\")\n",
    "        all_features.append(''.join(ch for ch in fs[0] if ch.isalnum()))\n",
    "        all_features.append(''.join(ch for ch in fs[1] if ch.isalnum()))\n",
    "        for i in range(0, len(fs)):\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "                features.append(res)\n",
    "            all_features.append(res)\n",
    "    top_features_cluster = sorted(list(set(features)))\n",
    "    print(sorted(list(set([int(re.findall(r'\\d+', r)[0]) for r in all_features]))))\n",
    "    print(top_features_cluster)\n",
    "    return top_features_cluster, all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_features_16, all_features_16 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster16\")\n",
    "top_features_80, all_features_80 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster80\")\n",
    "top_features_99 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster99\")\n",
    "top_features_6 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster6\")\n",
    "top_features_75 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster75\")\n",
    "top_features_21, all_features_21 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster21\")\n",
    "top_features_50 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster50\")\n",
    "top_features_11 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster11\")\n",
    "top_features_36, all_features_36 = get_top_measurable_features(samples_normalized_features_avg_df, \"cluster36\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted(list(set(top_features_21))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_most_different_measurable_features(samples_normalized_features_avg_df, \"cluster50\", \"cluster38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted(list(set(top_features_11).intersection(set(top_features_21)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(set(top_features_16).intersection(set(top_features_99)).difference(set(top_features_80).intersection(set(top_features_6)))))\n",
    "print(list(set(top_features_80).intersection(set(top_features_6)).difference(set(top_features_16).intersection(set(top_features_99)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_16 = []\n",
    "#top_features_16 = samples_normalized_features_avg_df.loc[\"cluster16\"].loc[samples_normalized_features_avg_df.loc[\"cluster16\"].abs() > .75].index.values\n",
    "#print(top_features_16)\n",
    "#print(len(top_features_16))\n",
    "[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False).index.values[:100]]\n",
    "[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False, ascending=False).index.values[:100]]\n",
    "all_features = []\n",
    "features = []\n",
    "for f in top_features_16:\n",
    "    fs = f.split(\",\")\n",
    "    all_features.append(''.join(ch for ch in fs[0] if ch.isalnum()))\n",
    "    all_features.append(''.join(ch for ch in fs[1] if ch.isalnum()))\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_16 = sorted(list(set(features)))\n",
    "print(len(list(set(all_features))))\n",
    "print(top_features_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_16 = []\n",
    "#top_features_16 = samples_normalized_features_avg_df.loc[\"cluster16\"].loc[samples_normalized_features_avg_df.loc[\"cluster16\"].abs() > .75].index.values\n",
    "#print(top_features_16)\n",
    "#print(len(top_features_16))\n",
    "[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False).index.values[:100]]\n",
    "[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False, ascending=False).index.values[:100]]\n",
    "all_features = []\n",
    "features = []\n",
    "for f in top_features_16:\n",
    "    fs = f.split(\",\")\n",
    "    all_features.append(''.join(ch for ch in fs[0] if ch.isalnum()))\n",
    "    all_features.append(''.join(ch for ch in fs[1] if ch.isalnum()))\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_16 = sorted(list(set(features)))\n",
    "print(len(list(set(all_features))))\n",
    "print(top_features_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "top_features_16 = []\n",
    "top_features_16 = samples_normalized_features_avg_df.loc[\"cluster16\"].loc[samples_normalized_features_avg_df.loc[\"cluster16\"].abs() > 1.].index.values\n",
    "print(top_features_16)\n",
    "print(len(top_features_16))\n",
    "#[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False).index.values[:50]]\n",
    "#[top_features_16.append(pair) for pair in samples_normalized_features_avg_df.iloc[16].sort(inplace=False, ascending=False).index.values[:50]]\n",
    "features = []\n",
    "for f in top_features_16:\n",
    "    fs = f.split(\",\")\n",
    "    for i in range(0, len(fs)):\n",
    "        if \"TRP\" in fs[i] or \"CYS\" in fs[i] or \"TYR\" in fs[i] or \"LYS\" in fs[i]:\n",
    "            res = int(re.findall(r'\\d+', fs[i])[0])\n",
    "            features.append(res)\n",
    "top_features_16 = list(set(features))\n",
    "print(top_features_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_normalized_features_avg_df.loc[\"cluster80\"].abs() > 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame(rfr.feature_importances_, index=aggregate_docking_msm.index, columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_df_rolling(deltas_tica.loc[importances_df.index][[\"tIC.1\", \"tIC.2\", \"tIC.3\", \"tIC.4\", \"tIC.5\", \"tm6_tm3_dist\", \"rmsd_npxxy_active\"]], \"%s/tICA_vs_rfr_importance_arrestin_agonists.pdf\" %docking_dir, return_fig=True, subplots=True, smoothing=10, include_original=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deltas_tica.loc[pd.DataFrame(rfr.feature_importances_, index=aggregate_docking_msm.index, columns=[\"RFR Importance\"]).sort(\"RFR Importance\", ascending=False, inplace=False).index].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deltas_tica.sort(\"nebivolol\").iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biased_antagonist_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = delta_delta_g[common_ligands].values.T\n",
    "print(np.shape(X))\n",
    "y = bret[\"Unnamed: 8\"].loc[common_ligands].values.reshape((-1,1))\n",
    "print(np.shape(y))\n",
    "X_train = X[:30,:]\n",
    "y_train = y[:30,:]\n",
    "X_test = X[30:,:]\n",
    "y_test = y[30:,:]\n",
    "rfr.fit(X_train,y_train)\n",
    "print(np.sqrt(np.mean(np.square(y_test-rfr.predict(X_test).reshape((-1,1))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_states = pd.DataFrame.from_dict(chosen_clusters, orient='index', dtype=int)\n",
    "chosen_states.columns = [\"n_occurrences\"]\n",
    "arrestin_biased_states = chosen_states.sort(\"n_occurrences\", ascending=False).index.values[0:20]\n",
    "print(arrestin_biased_states)\n",
    "deltas_tica = pd.concat([delta_delta_g, tica_cluster_averages_df, pnas_cluster_averages_df], axis=1)\n",
    "deltas_tica.loc[arrestin_biased_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed = pd.DataFrame(np.array([np.mean(experiments.values,axis=0), np.std(experiments.values, axis=0)]).T, columns=[\"means\", \"stds\"])\n",
    "#results[\"means\"] = experiments.values\n",
    "#results[\"stds\"] = np.std(experiments.values, axis=0)\n",
    "processed.index = experiments.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed.sort(\"means\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "reload(seaborn)\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.set_style(\"darkgrid\")\n",
    "experiments_sorted = experiments[experiments.median().order().index.values]\n",
    "g = (experiments_sorted\n",
    "    .pipe((sns.boxplot, 'data'), orient='h', showfliers=False))\n",
    "#g.set_xticklabels(experiments.columns.values, rotation=90)\n",
    "#sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df_agg = pd.read_csv(aggregate_docking, index_col=0)\n",
    "\n",
    "df = pd.read_csv(docking_multiple_ligands, index_col=0, skip_blank_lines=True).dropna()\n",
    "df.dropna(inplace=True)\n",
    "msm_obj = verboseload(msm_model_dir)\n",
    "\n",
    "msm_clusters = msm_obj.mapping_.keys()\n",
    "msm_cluster_names = [\"cluster%d\" %i for i in msm_clusters]\n",
    "msm_cluster_eq_pops = []\n",
    "for cluster_id in msm_clusters:\n",
    "    state_id = msm_obj.mapping_[cluster_id]\n",
    "    msm_cluster_eq_pops.append(msm_obj.populations_[state_id])\n",
    "msm_cluster_eq_pops = np.array(msm_cluster_eq_pops)\n",
    "msm_cluster_deltaG = -0.61 * np.log(msm_cluster_eq_pops)\n",
    "msm_cluster_eq_pops_df = pd.DataFrame(msm_cluster_eq_pops, index=msm_cluster_names)\n",
    "aggregate_docking_msm = df_agg.loc[msm_cluster_names]\n",
    "\n",
    "\n",
    "new_populations = copy.deepcopy(aggregate_docking_msm)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    new_populations[ligand] = np.exp(-1.0*(-1.0*aggregate_docking_msm[ligand].values+msm_cluster_deltaG)/0.61)\n",
    "\n",
    "Z = np.sum(new_populations.values, axis=0)\n",
    "for j, ligand in enumerate(aggregate_docking_msm.columns.values):\n",
    "    new_populations[ligand] = new_populations[ligand].values / Z[j]\n",
    "population_deltas = copy.deepcopy(new_populations)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    population_deltas[ligand] = population_deltas[ligand].values / msm_cluster_eq_pops\n",
    "new_energies = copy.deepcopy(new_populations)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    new_energies[ligand] = -.61 * np.log(new_populations[ligand])\n",
    "delta_delta_g = copy.deepcopy(new_energies)\n",
    "for ligand in aggregate_docking_msm.columns.values:\n",
    "    delta_delta_g[ligand] = new_energies[ligand].values - msm_cluster_deltaG\n",
    "\n",
    "train_biased_antagonists = [\" s-carvedilol\", \" nebivolol\", \" 3p0g_lig\"]\n",
    "docking_normalized = copy.deepcopy(population_deltas)\n",
    "docking_normalized[docking_normalized.columns.values] = scale(population_deltas.values)\n",
    "\n",
    "agonist_minus_antagonists = deltas_tica[train_agonists].mean(axis=1).values - deltas_tica[train_inverse_agonists + train_biased_antagonists].mean(axis=1).values\n",
    "agonist_minus_antagonists = (agonist_minus_antagonists - np.mean(agonist_minus_antagonists))/np.std(agonist_minus_antagonists)\n",
    "agonist_states = deltas_tica.iloc[np.where(agonist_minus_antagonists > 2.0)].loc[docking_normalized[train_agonists].min(axis=1) > 1.]\n",
    "\n",
    "bias_antagonist_minus_antagonists = deltas_tica[train_biased_antagonists].max(axis=1).values - deltas_tica[train_inverse_agonists].min(axis=1).values\n",
    "bias_antagonist_minus_antagonists = scale(bias_antagonist_minus_antagonists)\n",
    "\n",
    "bias_antagonist_minus_agonists = deltas_tica[[\" 3p0g_lig\"]].mean(axis=1).values - deltas_tica[train_agonists].mean(axis=1).values\n",
    "bias_antagonist_minus_agonists = scale(bias_antagonist_minus_agonists)\n",
    "indices = list(set(np.where(bias_antagonist_minus_antagonists < -.5)[0]))#.tolist()).intersection(set(np.where(bias_antagonist_minus_antagonists > 1.)[0].tolist())))\n",
    "biased_antagonist_states = deltas_tica.iloc[list(set(indices).intersection(set(np.where(np.max(scale(deltas_tica[train_biased_antagonists].values),axis=1) < -.5)[0])))]\n",
    "\n",
    "\n",
    "experiments2 = []\n",
    "n_experiments = 500\n",
    "for experiment in range(0, n_experiments):\n",
    "    docking_rows = []\n",
    "    docking_ids = []\n",
    "    for cluster_id in range(0, n_clusters):\n",
    "        sample_ids = [\"cluster%d_sample%d\" %(cluster_id, sample_id) for sample_id in range(0,n_samples)]\n",
    "        samples =  np.random.choice(sample_ids, len(sample_ids), replace=True)\n",
    "        docking_rows.append(np.mean(df.loc[samples].dropna().values, axis=0))\n",
    "        docking_ids.append(\"cluster%d\" %cluster_id)\n",
    "    docking = pd.DataFrame(docking_rows, columns=df.columns.values, index = docking_ids)\n",
    "    \n",
    "    aggregate_docking_msm = docking.loc[list(set(msm_cluster_names).intersection(set(docking.index.values)))]\n",
    "    \n",
    "\n",
    "    new_populations = copy.deepcopy(aggregate_docking_msm)\n",
    "    for ligand in aggregate_docking_msm.columns.values:\n",
    "        new_populations[ligand] = np.exp(-1.0*(-1.0*aggregate_docking_msm[ligand].values+msm_cluster_deltaG)/0.61)\n",
    "\n",
    "    Z = np.sum(new_populations.values, axis=0)\n",
    "    for j, ligand in enumerate(aggregate_docking_msm.columns.values):\n",
    "        new_populations[ligand] = new_populations[ligand].values / Z[j]\n",
    "    population_deltas = copy.deepcopy(new_populations)\n",
    "    for ligand in aggregate_docking_msm.columns.values:\n",
    "        population_deltas[ligand] = population_deltas[ligand].values / msm_cluster_eq_pops\n",
    "    new_energies = copy.deepcopy(new_populations)\n",
    "    for ligand in aggregate_docking_msm.columns.values:\n",
    "        new_energies[ligand] = -.61 * np.log(new_populations[ligand])\n",
    "    delta_delta_g = copy.deepcopy(new_energies)\n",
    "    for ligand in aggregate_docking_msm.columns.values:\n",
    "        delta_delta_g[ligand] = new_energies[ligand].values - msm_cluster_deltaG\n",
    "        \n",
    "    biased_population = new_populations.loc[biased_antagonist_states.index].sum(axis=0)\n",
    "    biased_antagonist_ori = msm_cluster_eq_pops_df.loc[biased_antagonist_states.index].sum().values[0]\n",
    "    biased_antagonist_change = biased_population.divide(biased_antagonist_ori)\n",
    "    \n",
    "    experiments2.append(biased_antagonist_change)\n",
    "\n",
    "experiments2 = pd.DataFrame(experiments2, columns = df.columns.values)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
